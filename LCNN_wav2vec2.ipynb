{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5ade6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jh20/narin/physionet/python-classifier-2022\")\n",
    "from helper_code import *\n",
    "import numpy as np, scipy as sp, scipy.stats, os, joblib\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37523e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import soundfile\n",
    "import librosa\n",
    "import torch\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer, Wav2Vec2Model,Wav2Vec2Config, Wav2Vec2FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626f5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "def get_logger(filename):\n",
    "    # Logging configuration: set the basic configuration of the logging system\n",
    "    log_formatter = logging.Formatter(fmt='%(asctime)s [%(processName)s, %(process)s] [%(levelname)-5.5s]  %(message)s',\n",
    "                                      datefmt='%m-%d %H:%M')\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    # File logger\n",
    "    file_handler = logging.FileHandler(\"{}.log\".format(filename))\n",
    "    file_handler.setFormatter(log_formatter)\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(file_handler)\n",
    "    # Stderr logger\n",
    "    std_handler = logging.StreamHandler(sys.stdout)\n",
    "    std_handler.setFormatter(log_formatter)\n",
    "    std_handler.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(std_handler)\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b42d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute a binary confusion matrix, where the columns are the expert labels and the rows are the classifier labels.\n",
    "def compute_confusion_matrix(labels, outputs):\n",
    "    assert(np.shape(labels)[0] == np.shape(outputs)[0])\n",
    "    assert(all(value in (0, 1, True, False) for value in np.unique(labels)))\n",
    "    assert(all(value in (0, 1, True, False) for value in np.unique(outputs)))\n",
    "\n",
    "    num_patients = np.shape(labels)[0]\n",
    "    num_label_classes = np.shape(labels)[1]\n",
    "    num_output_classes = np.shape(outputs)[1]\n",
    "\n",
    "    A = np.zeros((num_output_classes, num_label_classes))\n",
    "    for k in range(num_patients):\n",
    "        for i in range(num_output_classes):\n",
    "            for j in range(num_label_classes):\n",
    "                if outputs[k, i] == 1 and labels[k, j] == 1:\n",
    "                    A[i, j] += 1\n",
    "\n",
    "    return A\n",
    "\n",
    "# Compute binary one-vs-rest confusion matrices, where the columns are the expert labels and the rows are the classifier labels.\n",
    "def compute_one_vs_rest_confusion_matrix(labels, outputs):\n",
    "    assert(np.shape(labels) == np.shape(outputs))\n",
    "    assert(all(value in (0, 1, True, False) for value in np.unique(labels)))\n",
    "    assert(all(value in (0, 1, True, False) for value in np.unique(outputs)))\n",
    "\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    A = np.zeros((num_classes, 2, 2))\n",
    "    for i in range(num_patients):\n",
    "        for j in range(num_classes):\n",
    "            if labels[i, j] == 1 and outputs[i, j] == 1: # TP\n",
    "                A[j, 0, 0] += 1\n",
    "            elif labels[i, j] == 0 and outputs[i, j] == 1: # FP\n",
    "                A[j, 0, 1] += 1\n",
    "            elif labels[i, j] == 1 and outputs[i, j] == 0: # FN\n",
    "                A[j, 1, 0] += 1\n",
    "            elif labels[i, j] == 0 and outputs[i, j] == 0: # TN\n",
    "                A[j, 1, 1] += 1\n",
    "\n",
    "    return A\n",
    "\n",
    "# Compute macro F-measure.\n",
    "def compute_f_measure(labels, outputs):\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    A = compute_one_vs_rest_confusion_matrix(labels, outputs)\n",
    "\n",
    "    f_measure = np.zeros(num_classes)\n",
    "    for k in range(num_classes):\n",
    "        tp, fp, fn, tn = A[k, 0, 0], A[k, 0, 1], A[k, 1, 0], A[k, 1, 1]\n",
    "        if 2 * tp + fp + fn > 0:\n",
    "            f_measure[k] = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "        else:\n",
    "            f_measure[k] = float('nan')\n",
    "\n",
    "    if np.any(np.isfinite(f_measure)):\n",
    "        macro_f_measure = np.nanmean(f_measure)\n",
    "    else:\n",
    "        macro_f_measure = float('nan')\n",
    "\n",
    "    return macro_f_measure, f_measure\n",
    "\n",
    "# Compute accuracy.\n",
    "def compute_accuracy(labels, outputs):\n",
    "    # Compute confusion matrix.\n",
    "    assert(np.shape(labels) == np.shape(outputs))\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "    A = compute_confusion_matrix(labels, outputs)\n",
    "\n",
    "    # Compute accuracy.\n",
    "    if np.sum(A) > 0:\n",
    "        accuracy = np.trace(A) / np.sum(A)\n",
    "    else:\n",
    "        accuracy = float('nan')\n",
    "\n",
    "    # Compute per-class accuracy.\n",
    "    accuracy_classes = np.zeros(num_classes)\n",
    "    for i in range(num_classes):\n",
    "        if np.sum(A[:, i]) > 0:\n",
    "            accuracy_classes[i] = A[i, i] / np.sum(A[:, i])\n",
    "        else:\n",
    "            accuracy_classes[i] = float('nan')\n",
    "\n",
    "    return accuracy, accuracy_classes\n",
    "\n",
    "# Compute accuracy.\n",
    "def compute_weighted_accuracy(labels, outputs, classes):\n",
    "    # Define constants.\n",
    "    if classes == ['Present', 'Unknown', 'Absent']:\n",
    "        weights = np.array([[5, 3, 1], [5, 3, 1], [5, 3, 1]])\n",
    "    elif classes == ['Abnormal', 'Normal']:\n",
    "        weights = np.array([[5, 1], [5, 1]])\n",
    "    else:\n",
    "        raise NotImplementedError('Weighted accuracy undefined for classes {}'.format(', '.join(classes)))\n",
    "\n",
    "    # Compute confusion matrix.\n",
    "    assert(np.shape(labels) == np.shape(outputs))\n",
    "    A = compute_confusion_matrix(labels, outputs)\n",
    "\n",
    "    # Multiply the confusion matrix by the weight matrix.\n",
    "    assert(np.shape(A) == np.shape(weights))\n",
    "    B = weights * A\n",
    "\n",
    "    # Compute weighted_accuracy.\n",
    "    if np.sum(B) > 0:\n",
    "        weighted_accuracy = np.trace(B) / np.sum(B)\n",
    "    else:\n",
    "        weighted_accuracy = float('nan')\n",
    "\n",
    "    return weighted_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5f6c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import F1\n",
    "from torchmetrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29c20b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LCNN(nn.Module):\n",
    "\n",
    "    def __init__(self,mode):\n",
    "\n",
    "        super(LCNN, self).__init__()\n",
    "        '''input : (B,1,F,T)'''\n",
    "        \n",
    "        self.mode = mode\n",
    "        \n",
    "        self.conv2d_1  = nn.Conv2d(1, 32, kernel_size=(5,5), stride=(1,1), padding=(2,2))\n",
    "        self.conv2d_2  = nn.Conv2d(1, 32, kernel_size=(5,5), stride=(1,1), padding=(2,2))\n",
    "        \n",
    "        self.max2d_1 = nn.MaxPool2d(kernel_size =(2,2), stride=(2,2),padding = 0)\n",
    "        \n",
    "        self.conv2d_3  = nn.Conv2d(32, 32, kernel_size=(1,1), stride=(1,1))\n",
    "        self.conv2d_4  = nn.Conv2d(32, 32, kernel_size=(1,1), stride=(1,1))\n",
    "        \n",
    "        self.bn2d_1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2d_5  = nn.Conv2d(32, 48, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.conv2d_6  = nn.Conv2d(32, 48, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        \n",
    "        self.max2d_2 = nn.MaxPool2d(kernel_size =(2,2), stride=(2,2),padding = 0)\n",
    "        self.bn2d_2 = nn.BatchNorm2d(48)\n",
    "        \n",
    "        \n",
    "        self.conv2d_7  = nn.Conv2d(48, 48, kernel_size=(1,1), stride=(1,1))\n",
    "        self.conv2d_8  = nn.Conv2d(48, 48, kernel_size=(1,1), stride=(1,1))\n",
    "        \n",
    "        self.bn2d_3 = nn.BatchNorm2d(48)\n",
    "        \n",
    "        self.conv2d_9  = nn.Conv2d(48, 64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.conv2d_10  = nn.Conv2d(48, 64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        \n",
    "        self.max2d_3 = nn.MaxPool2d(kernel_size =(2,2), stride=(2,2),padding = 0)\n",
    "        \n",
    "        self.conv2d_11  = nn.Conv2d(64, 64, kernel_size=(1,1), stride=(1,1))\n",
    "        self.conv2d_12  = nn.Conv2d(64, 64, kernel_size=(1,1), stride=(1,1))\n",
    "        \n",
    "        self.bn2d_4 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2d_13  = nn.Conv2d(64, 32, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        self.conv2d_14  = nn.Conv2d(64, 32, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n",
    "        \n",
    "        self.bn2d_5 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        \n",
    "        self.conv2d_15  = nn.Conv2d(32, 32, kernel_size=(1,1), stride=(1,1))\n",
    "        self.conv2d_16  = nn.Conv2d(32, 32, kernel_size=(1,1), stride=(1,1))\n",
    "        \n",
    "        self.bn2d_6 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        \n",
    "        self.conv2d_17  = nn.Conv2d(32, 32, kernel_size=(1,1), stride=(1,1))\n",
    "        self.conv2d_18  = nn.Conv2d(32, 32, kernel_size=(1,1), stride=(1,1))\n",
    "        \n",
    "        self.max2d_4 = nn.MaxPool2d(kernel_size =(2,2), stride=(2,2),padding = 0)\n",
    "        \n",
    "        self.adaptavg = nn.AdaptiveAvgPool2d(1)\n",
    "        \n",
    "        \n",
    "#        self.fc1 = nn.Linear(64, 128)\n",
    "        \n",
    "        if self.mode == 'murmur' :\n",
    "            self.fc_mur = nn.Sequential(\n",
    "                                        nn.Linear(32,3),\n",
    "#                                         nn.Sigmoid()\n",
    "                                        )\n",
    "        elif self.mode == 'outcome' :\n",
    "            self.fc_out = nn.Sequential(\n",
    "                                        nn.Linear(128,32),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Linear(32,2)\n",
    "                                        )\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        x1 = self.conv2d_1(input)\n",
    "        x2 = self.conv2d_2(input)\n",
    "        max1 = torch.maximum(x1,x2)\n",
    "        x = self.max2d_1(max1)\n",
    "        \n",
    "        x3 = self.conv2d_3(x)\n",
    "        x4 = self.conv2d_4(x)\n",
    "        max2 = torch.maximum(x3,x4)\n",
    "        x = self.bn2d_1(max2)\n",
    "        \n",
    "        x5 = self.conv2d_5(x)\n",
    "        x6 = self.conv2d_6(x)\n",
    "        max3 = torch.maximum(x5,x6)\n",
    "        x = self.max2d_2(max3)\n",
    "        x = self.bn2d_2(x)\n",
    "        \n",
    "        x7 = self.conv2d_7(x)\n",
    "        x8 = self.conv2d_8(x)\n",
    "        max4 = torch.maximum(x7,x8)\n",
    "        x = self.bn2d_3(max4)\n",
    "        \n",
    "        x9 = self.conv2d_9(x)\n",
    "        x10 = self.conv2d_10(x)\n",
    "        max5 = torch.maximum(x9,x10)\n",
    "        x = self.max2d_3(max5)\n",
    "        \n",
    "        x11 = self.conv2d_11(x)\n",
    "        x12 = self.conv2d_12(x)\n",
    "        max6 = torch.maximum(x11,x12)\n",
    "        x = self.bn2d_4(max6)\n",
    "        \n",
    "        x13 = self.conv2d_13(x)\n",
    "        x14 = self.conv2d_14(x)\n",
    "        max7 = torch.maximum(x13,x14)\n",
    "        x = self.bn2d_5(max7)\n",
    "        \n",
    "        x15 = self.conv2d_15(x)\n",
    "        x16 = self.conv2d_16(x)\n",
    "        max8 = torch.maximum(x15,x16)\n",
    "        x = self.bn2d_6(max8)\n",
    "        \n",
    "        x17 = self.conv2d_17(x)\n",
    "        x18 = self.conv2d_18(x)\n",
    "        max9 = torch.maximum(x17,x18)\n",
    "        x = self.max2d_4(max9)\n",
    "        \n",
    "        x = self.adaptavg(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        \n",
    "#        x = self.fc1(x)\n",
    "        \n",
    "        \n",
    "        if self.mode == 'murmur' :\n",
    "            out = self.fc_mur(x)\n",
    "        elif self.mode == 'outcome' :\n",
    "            out = self.fc_out(x)\n",
    "#        out = {'murmur':out1, 'outcome':out2}\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48ea6cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, warnings, sys\n",
    "import torch\n",
    "\n",
    "sys.path.append('/home/jh20/narin/dcase/DESED_task')\n",
    "sys.path.append('/home/jh20/narin/dcase/DESED_task/recipes/dcase2022_task4_baseline')\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description = \"HMD_trainer\")\n",
    "## Training Settings\n",
    "parser.add_argument('--train_data_folder',    default='/home/jh20/Data/nr_data/ECG/Physionet2022/physionet.org/files/circor-heart-sound/1.0.3/train/',     help='train data path')\n",
    "parser.add_argument('--valid_data_folder',    default='/home/jh20/Data/nr_data/ECG/Physionet2022/physionet.org/files/circor-heart-sound/1.0.3/validation/',     help='validation data path')\n",
    "parser.add_argument('--train_feature_folder',    default='/home/jh20/Data/nr_data/ECG/Physionet2022/physionet.org/files/circor-heart-sound/1.0.3/train_wav2vec2/',     help='train feature path')\n",
    "parser.add_argument('--valid_feature_folder',    default='/home/jh20/Data/nr_data/ECG/Physionet2022/physionet.org/files/circor-heart-sound/1.0.3/validation_wav2vec2/',     help='validation feature path')\n",
    "parser.add_argument('--output_folder',    default='./output_folder_LCNN',     help='output folder')\n",
    "parser.add_argument(\"--mode\",default=\"murmur\", type=str, help=\"mode : murmur/outcome\")\n",
    "parser.add_argument(\"--lr\",default=1e-3, type=float, help=\"learning rate\")\n",
    "parser.add_argument(\"--minibatchsize_train\", default=32, type=int)\n",
    "parser.add_argument(\"--minibatchsize_valid\", default=1, type=int)\n",
    "parser.add_argument(\"--train_num_workers\", default=8, type=int, help=\"number of training workers\")\n",
    "parser.add_argument(\"--dev_num_workers\", default=1, type=int, help=\"number of validation workers\")\n",
    "parser.add_argument(\"--seed\", default=617, type=int)\n",
    "parser.add_argument(\"--model_path\", default='./hmd_LCNN', type=str)\n",
    "parser.add_argument(\"--logdir\", default='./log_hmd_LCNN/', type=str)\n",
    "parser.add_argument(\"--model_name\", default='hmd_LCNN_model_murmur', type=str)\n",
    "parser.add_argument(\"--start_iter\", default=0, type=int)\n",
    "parser.add_argument(\"--end_iter\", default=80, type=int)\n",
    "parser.add_argument(\"--gpu\", default=\"0\", type=str)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(\"ignore\")\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3f291cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_files = glob.glob(args.train_data_folder + '*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee61c679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'84780_AV.pk'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_files[0].split('/')[-1].replace('wav','pk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "402a493a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jh20/Data/nr_data/ECG/Physionet2022/physionet.org/files/circor-heart-sound/1.0.3/train_wav2vec2/'+ '84780_AV.pickle' ,'rb') as fr:\n",
    "    feature = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "70358f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5f4eff5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0459,  0.0593, -0.0603,  ..., -0.1019,  0.0114,  0.0242],\n",
       "         [-0.0499,  0.0556, -0.0516,  ..., -0.0988,  0.0102,  0.0215],\n",
       "         [-0.0484,  0.0601, -0.0551,  ..., -0.1023,  0.0086,  0.0161],\n",
       "         ...,\n",
       "         [-0.0464,  0.0588, -0.0586,  ..., -0.0926,  0.0141,  0.0075],\n",
       "         [-0.0507,  0.0554, -0.0463,  ..., -0.0952,  0.0089,  0.0145],\n",
       "         [-0.0652,  0.0647, -0.0358,  ..., -0.1260,  0.0051,  0.0213]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "260a9edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2532/2532 [06:41<00:00,  6.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "wav_files = glob.glob(args.train_data_folder + '*.wav')\n",
    "# wav2vec2 = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "for i in tqdm(range(len(wav_files))):\n",
    "    current_recording = read_recording(wav_files[i])\n",
    "    current_recording = current_recording.reshape(1,80000)\n",
    "    feature = wav2vec2(torch.tensor(current_recording, dtype=torch.float32))\n",
    "    feature.requires_grad = False\n",
    "    fnm = wav_files[i].split('/')[-1].replace('wav','pickle')\n",
    "    with open('/home/jh20/Data/nr_data/ECG/Physionet2022/physionet.org/files/circor-heart-sound/1.0.3/train_wav2vec2/'+ fnm ,'wb') as fw:\n",
    "        pickle.dump(feature[0],fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ccff1c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 631/631 [01:38<00:00,  6.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "wav_files = glob.glob(args.valid_data_folder + '*.wav')\n",
    "# wav2vec2 = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "for i in tqdm(range(len(wav_files))):\n",
    "    current_recording = read_recording(wav_files[i])\n",
    "    current_recording = current_recording.reshape(1,80000)\n",
    "    feature = wav2vec2(torch.tensor(current_recording, dtype=torch.float32))\n",
    "    feature.requires_grad = False\n",
    "    fnm = wav_files[i].split('/')[-1].replace('wav','pickle')\n",
    "    with open('/home/jh20/Data/nr_data/ECG/Physionet2022/physionet.org/files/circor-heart-sound/1.0.3/validation_wav2vec2/'+ fnm ,'wb') as fw:\n",
    "        pickle.dump(feature[0],fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "de6c3fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2532"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_files = glob.glob(args.train_data_folder + '*.wav')\n",
    "len(wav_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e81d4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,DataLoader, RandomSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"/home/jh20/narin/physionet/python-classifier-2022\")\n",
    "from helper_code import *\n",
    "import torchaudio\n",
    "import random\n",
    "import numpy as np\n",
    "import librosa\n",
    "import glob\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_recording(wav_fn, audio_length= 20, sr= 4000):\n",
    "\n",
    "    recording, frequency = load_wav_file(wav_fn)\n",
    "\n",
    "\n",
    "    length = audio_length*sr\n",
    "    if recording.shape[0] <= length:\n",
    "        shortage = length - recording.shape[0]\n",
    "        recording = np.pad(recording, (0, shortage), 'wrap')\n",
    "    start_frame = np.int64(random.random()*(recording.shape[0]-length))\n",
    "    recording = recording[start_frame:start_frame + length] \n",
    "\n",
    "    return recording\n",
    "\n",
    "\n",
    "\n",
    "class train_loader(Dataset):\n",
    "    def __init__(self,data_folder, feature_folder, **kwargs):\n",
    "        self.data_folder = data_folder\n",
    "        self.feature_folder = feature_folder\n",
    "        \n",
    "        \n",
    "        self.feature_file = glob.glob(feature_folder + '*.pickle')\n",
    "        self.wav_files = glob.glob(data_folder + '*.wav')\n",
    "        self.num_feature_files = len(self.feature_file)\n",
    "        \n",
    "        self.murmur_classes = ['Present', 'Absent']\n",
    "        self.num_murmur_classes = len(self.murmur_classes)\n",
    "        self.outcome_classes = ['Abnormal', 'Normal']\n",
    "        self.num_outcome_classes = len(self.outcome_classes)\n",
    "        \n",
    "        self.age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "        self.recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        examples = {}\n",
    "        for filename in self.feature_file:\n",
    "            current_patient_id = filename.split('/')[-1].split('_')[0]\n",
    "            current_txt_file = self.data_folder + str(current_patient_id) + '.txt'\n",
    "            with open(current_txt_file, 'r') as f:\n",
    "                current_patient_data = f.read()\n",
    "            current_loc = filename.split('/')[-1].split('.')[0].split('_')[1]\n",
    "            if filename.split('/')[-1].split('.')[0]  not in examples.keys():\n",
    "                current_feature_data = filename.split('/')[-1].split('.')[0]\n",
    "                with open(filename, 'rb') as fr:\n",
    "                    feature = pickle.load(fr)\n",
    "                examples[current_feature_data] = {\n",
    "                    \"id\" : current_patient_id,\n",
    "                    \"txt_fn\" : current_txt_file,   #txt,\n",
    "                    \"feature\" : feature,  #wav\n",
    "                    \"num_location\": get_num_locations(current_patient_data),\n",
    "                    \"frequency\" : get_frequency(current_patient_data),\n",
    "                    \"location\" : current_loc,\n",
    "                    \"age\" : get_age(current_patient_data),\n",
    "                    \"sex\" : get_sex(current_patient_data),\n",
    "                    \"height\" : get_height(current_patient_data),\n",
    "                    \"weight\" : get_weight(current_patient_data),\n",
    "                    \"pregnancy_status\" : get_pregnancy_status(current_patient_data),\n",
    "                    \"murmur\" : get_murmur(current_patient_data),\n",
    "                    \"outcome\" : get_outcome(current_patient_data)\n",
    "\n",
    "                }\n",
    "        self.examples = examples\n",
    "        self.examples_list = list(examples.keys())\n",
    "        \n",
    "        \n",
    "        if len(self.examples_list) != self.num_feature_files:\n",
    "            raise ValueError('length is different!')\n",
    "    def __len__(self):\n",
    "        return len(self.examples_list)\n",
    "    \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # patient info\n",
    "        current_feature_dict = self.examples[self.examples_list[index]]\n",
    "        current_patient_data = load_patient_data(current_feature_dict[\"txt_fn\"])\n",
    "\n",
    "        \n",
    "        # wav2vec2 feature\n",
    "        \n",
    "        feature = current_feature_dict[\"feature\"]\n",
    "        feature.requires_grad = False\n",
    "        \n",
    "        \n",
    "#         #log mel feature\n",
    "#         log_mel_feature = librosa.power_to_db(librosa.feature.melspectrogram(y = current_recording.astype(np.float32),\n",
    "#                                                          sr= 4000,\n",
    "#                                                          n_mels=128,\n",
    "#                                                          n_fft=400, \n",
    "#                                                          hop_length=128, \n",
    "#                                                          win_length=400))\n",
    "        \n",
    "#         # age\n",
    "#         current_patient_age = current_wav_dict[\"age\"]\n",
    "#         current_age_group = np.zeros(6, dtype=np.float32)\n",
    "#         if current_patient_age in self.age_classes:\n",
    "#             j = self.age_classes.index(current_patient_age)\n",
    "#             current_age_group[j] = 1.0\n",
    "#         else :\n",
    "#             current_age_group[5] = 1.0\n",
    "            \n",
    "            \n",
    "#         # sex\n",
    "#         sex = current_wav_dict[\"sex\"]\n",
    "#         sex_feature = np.zeros(2, dtype=np.float32)\n",
    "#         if compare_strings(sex, 'Female'):\n",
    "#             sex_feature[0] = 1.0\n",
    "#         elif compare_strings(sex, 'Male'):\n",
    "#             sex_feature[1] = 1.0\n",
    "            \n",
    "#         # height and weight.\n",
    "#         height = current_wav_dict[\"height\"]\n",
    "#         weight = current_wav_dict[\"weight\"]\n",
    "        \n",
    "#         ## simple impute\n",
    "#         if math.isnan(height) :\n",
    "#             height = 110.846  #mean\n",
    "#         if math.isnan(weight) :\n",
    "#             weight = 23.767   #mean\n",
    "            \n",
    "#         height_weight = np.array([height, weight], dtype=np.float32)\n",
    "        \n",
    "        \n",
    "#         # Extract pregnancy\n",
    "#         preg_feature = np.zeros(2, dtype=np.float32)\n",
    "#         is_pregnant = current_wav_dict[\"pregnancy_status\"]\n",
    "#         if is_pregnant == True:\n",
    "#             preg_feature[0] = 1.0\n",
    "#         elif is_pregnant == False:\n",
    "#             preg_feature[1] = 1.0\n",
    "\n",
    "#         # Extract location\n",
    "#         location = current_wav_dict[\"location\"]\n",
    "#         num_recording_locations = len(self.recording_locations)\n",
    "#         loc_feature = np.zeros(num_recording_locations, dtype=np.float32)\n",
    "#         if location in self.recording_locations:\n",
    "#             j = self.recording_locations.index(location)\n",
    "#             loc_feature[j] = 1.0\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # label\n",
    "        \n",
    "        current_murmur = np.zeros(self.num_murmur_classes, dtype=np.float32)\n",
    "        murmur = get_murmur(current_patient_data)\n",
    "        if murmur in self.murmur_classes:\n",
    "            j = self.murmur_classes.index(murmur)\n",
    "            current_murmur[j] = 1\n",
    "        else:\n",
    "            current_murmur[j] = 1\n",
    "\n",
    "\n",
    "        current_outcome = np.zeros(self.num_outcome_classes, dtype=np.float32)\n",
    "        outcome = get_outcome(current_patient_data)\n",
    "        if outcome in self.outcome_classes:\n",
    "            j = self.outcome_classes.index(outcome)\n",
    "            current_outcome[j] = 1\n",
    "            \n",
    "\n",
    "\n",
    "        \n",
    "        return feature, current_murmur, current_outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3a271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85374487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77fdfd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_recording = read_recording('/home/jh20/Data/nr_data/ECG/Physionet2022/physionet.org/files/circor-heart-sound/1.0.3/train/84780_AV.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1146ed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_files = glob.glob(args.train_data_folder + '*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba3056f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jh20/Data/nr_data/ECG/Physionet2022/physionet.org/files/circor-heart-sound/1.0.3/train/84780_AV.wav'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b37ab64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -499.,  -575., -1087.,  ..., -3010.,    57.,  2857.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(current_recording, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc74ddb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 80000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_recording.reshape(1,80000).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07275c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1432348f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available devices  1\n"
     ]
    }
   ],
   "source": [
    "# Find data files.\n",
    "# if verbose >= 1:\n",
    "#     print('Finding data files...')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "    \n",
    "GPU_NUM = args.gpu # 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "\n",
    "# Find the patient data files.\n",
    "patient_files = find_patient_files(args.train_data_folder)\n",
    "num_patient_files = len(patient_files)\n",
    "\n",
    "if num_patient_files==0:\n",
    "    raise Exception('No data was provided.')\n",
    "\n",
    "# Create a folder for the model if it does not already exist.\n",
    "os.makedirs(args.model_path, exist_ok=True)\n",
    "os.makedirs(args.logdir, exist_ok=True)\n",
    "\n",
    "open(args.logdir + 'score.txt', \"a+\")\n",
    "score_file = open(args.logdir + 'score.txt', \"a+\")\n",
    "\n",
    "\n",
    "model_folder = args.model_path\n",
    "log_dir = args.logdir\n",
    "logger = get_logger(log_dir + '/' + model_folder)\n",
    "\n",
    "# Define the model\n",
    "lcnn_model = LCNN(\"murmur\")\n",
    "lcnn_model = lcnn_model.cuda(device)\n",
    "\n",
    "# Define the metrics\n",
    "accuracy = Accuracy(num_classes=3, multiclass=True)\n",
    "f1 = F1(num_classes=3,average='macro', multiclass=True)\n",
    "\n",
    "# optimizer, loss\n",
    "opt = torch.optim.Adam(lcnn_model.parameters(), lr=args.lr, betas=(0.9, 0.999))\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, 0.91)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "#data loader\n",
    "trainset = train_loader(args.train_data_folder, args.train_feature_folder )\n",
    "validset = train_loader(args.valid_data_folder, args.valid_feature_folder )\n",
    "point_sampler = RandomSampler(trainset)\n",
    "\n",
    "dataloader_train = DataLoader(dataset=trainset,\n",
    "                    batch_size=args.minibatchsize_train,\n",
    "                           sampler =point_sampler,\n",
    "                           num_workers=args.train_num_workers)\n",
    "dataloader_valid = DataLoader(dataset=validset,\n",
    "                    batch_size=args.minibatchsize_valid,\n",
    "                           num_workers=args.dev_num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5298da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c  = next(iter(dataloader_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0298c242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386dadde",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64e0e934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00091\n",
      "08-08 01:51 [MainProcess, 13692] [INFO ]  Iteration:0, train loss = 0.611032 ,train F1 = 0.417418 ,train ACC = 0.791074 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:51 [MainProcess, 13692] [INFO ]  valid Epoch:0, Train loss=0.6110, Valid loss=0.6327,Valid F1=0.4355,Valid ACC=0.7829, Valid weighted acc=0.5463\n",
      "08-08 01:51 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.78766417503357 seconds.\n",
      "08-08 01:51 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0008281\n",
      "08-08 01:51 [MainProcess, 13692] [INFO ]  Iteration:1, train loss = 0.574782 ,train F1 = 0.437016 ,train ACC = 0.802923 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 401.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:51 [MainProcess, 13692] [INFO ]  valid Epoch:1, Train loss=0.5748, Valid loss=0.6104,Valid F1=0.4328,Valid ACC=0.8003, Valid weighted acc=0.5291\n",
      "08-08 01:51 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.614434719085693 seconds.\n",
      "08-08 01:51 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0007535710000000001\n",
      "08-08 01:51 [MainProcess, 13692] [INFO ]  Iteration:2, train loss = 0.551302 ,train F1 = 0.456477 ,train ACC = 0.813191 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 395.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:51 [MainProcess, 13692] [INFO ]  valid Epoch:2, Train loss=0.5513, Valid loss=0.5901,Valid F1=0.4503,Valid ACC=0.8051, Valid weighted acc=0.5546\n",
      "08-08 01:51 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.758727312088013 seconds.\n",
      "08-08 01:51 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0006857496100000001\n",
      "08-08 01:52 [MainProcess, 13692] [INFO ]  Iteration:3, train loss = 0.553894 ,train F1 = 0.473634 ,train ACC = 0.820300 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 394.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:52 [MainProcess, 13692] [INFO ]  valid Epoch:3, Train loss=0.5539, Valid loss=0.6005,Valid F1=0.4528,Valid ACC=0.8082, Valid weighted acc=0.5562\n",
      "08-08 01:52 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.73708486557007 seconds.\n",
      "08-08 01:52 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0006240321451000001\n",
      "08-08 01:52 [MainProcess, 13692] [INFO ]  Iteration:4, train loss = 0.522708 ,train F1 = 0.484440 ,train ACC = 0.826619 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 403.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:52 [MainProcess, 13692] [INFO ]  valid Epoch:4, Train loss=0.5227, Valid loss=0.6463,Valid F1=0.4396,Valid ACC=0.7987, Valid weighted acc=0.5414\n",
      "08-08 01:52 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.738707542419434 seconds.\n",
      "08-08 01:52 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0005678692520410001\n",
      "08-08 01:52 [MainProcess, 13692] [INFO ]  Iteration:5, train loss = 0.521976 ,train F1 = 0.485539 ,train ACC = 0.825829 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 404.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:52 [MainProcess, 13692] [INFO ]  valid Epoch:5, Train loss=0.5220, Valid loss=0.5860,Valid F1=0.4720,Valid ACC=0.8051, Valid weighted acc=0.6005\n",
      "08-08 01:52 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.661031246185303 seconds.\n",
      "08-08 01:52 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00051676101935731\n",
      "08-08 01:52 [MainProcess, 13692] [INFO ]  Iteration:6, train loss = 0.511721 ,train F1 = 0.487437 ,train ACC = 0.826224 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 402.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:53 [MainProcess, 13692] [INFO ]  valid Epoch:6, Train loss=0.5117, Valid loss=0.5824,Valid F1=0.4745,Valid ACC=0.8130, Valid weighted acc=0.5947\n",
      "08-08 01:53 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.74952006340027 seconds.\n",
      "08-08 01:53 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00047025252761515214\n",
      "08-08 01:53 [MainProcess, 13692] [INFO ]  Iteration:7, train loss = 0.502908 ,train F1 = 0.495161 ,train ACC = 0.832938 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 401.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:53 [MainProcess, 13692] [INFO ]  valid Epoch:7, Train loss=0.5029, Valid loss=0.6108,Valid F1=0.4546,Valid ACC=0.8098, Valid weighted acc=0.5570\n",
      "08-08 01:53 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.6581609249115 seconds.\n",
      "08-08 01:53 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00042792980012978845\n",
      "08-08 01:53 [MainProcess, 13692] [INFO ]  Iteration:8, train loss = 0.506569 ,train F1 = 0.499510 ,train ACC = 0.834913 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 406.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:53 [MainProcess, 13692] [INFO ]  valid Epoch:8, Train loss=0.5066, Valid loss=0.6084,Valid F1=0.4599,Valid ACC=0.8067, Valid weighted acc=0.5718\n",
      "08-08 01:53 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.679033041000366 seconds.\n",
      "08-08 01:53 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0003894161181181075\n",
      "08-08 01:53 [MainProcess, 13692] [INFO ]  Iteration:9, train loss = 0.480856 ,train F1 = 0.512784 ,train ACC = 0.842022 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 399.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:53 [MainProcess, 13692] [INFO ]  valid Epoch:9, Train loss=0.4809, Valid loss=0.5678,Valid F1=0.4644,Valid ACC=0.8146, Valid weighted acc=0.5726\n",
      "08-08 01:53 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.676411867141724 seconds.\n",
      "08-08 01:53 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0003543686674874778\n",
      "08-08 01:54 [MainProcess, 13692] [INFO ]  Iteration:10, train loss = 0.472420 ,train F1 = 0.511944 ,train ACC = 0.842812 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 402.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:54 [MainProcess, 13692] [INFO ]  valid Epoch:10, Train loss=0.4724, Valid loss=0.5685,Valid F1=0.4782,Valid ACC=0.8130, Valid weighted acc=0.6046\n",
      "08-08 01:54 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.646639108657837 seconds.\n",
      "08-08 01:54 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00032247548741360483\n",
      "08-08 01:54 [MainProcess, 13692] [INFO ]  Iteration:11, train loss = 0.443539 ,train F1 = 0.522265 ,train ACC = 0.847551 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 399.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:54 [MainProcess, 13692] [INFO ]  valid Epoch:11, Train loss=0.4435, Valid loss=0.6119,Valid F1=0.4643,Valid ACC=0.8114, Valid weighted acc=0.5742\n",
      "08-08 01:54 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.741406679153442 seconds.\n",
      "08-08 01:54 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0002934526935463804\n",
      "08-08 01:54 [MainProcess, 13692] [INFO ]  Iteration:12, train loss = 0.438125 ,train F1 = 0.534728 ,train ACC = 0.856240 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 399.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:54 [MainProcess, 13692] [INFO ]  valid Epoch:12, Train loss=0.4381, Valid loss=0.6096,Valid F1=0.4727,Valid ACC=0.8019, Valid weighted acc=0.6054\n",
      "08-08 01:54 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.708760499954224 seconds.\n",
      "08-08 01:54 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00026704195112720616\n",
      "08-08 01:55 [MainProcess, 13692] [INFO ]  Iteration:13, train loss = 0.432237 ,train F1 = 0.528426 ,train ACC = 0.849526 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 403.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:55 [MainProcess, 13692] [INFO ]  valid Epoch:13, Train loss=0.4322, Valid loss=0.6156,Valid F1=0.4705,Valid ACC=0.8130, Valid weighted acc=0.5849\n",
      "08-08 01:55 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.722155809402466 seconds.\n",
      "08-08 01:55 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00024300817552575763\n",
      "08-08 01:55 [MainProcess, 13692] [INFO ]  Iteration:14, train loss = 0.411449 ,train F1 = 0.547037 ,train ACC = 0.863349 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 401.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:55 [MainProcess, 13692] [INFO ]  valid Epoch:14, Train loss=0.4114, Valid loss=0.6061,Valid F1=0.4730,Valid ACC=0.8130, Valid weighted acc=0.5915\n",
      "08-08 01:55 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.700756072998047 seconds.\n",
      "08-08 01:55 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00022113743972843945\n",
      "08-08 01:55 [MainProcess, 13692] [INFO ]  Iteration:15, train loss = 0.387993 ,train F1 = 0.554090 ,train ACC = 0.866904 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:55 [MainProcess, 13692] [INFO ]  valid Epoch:15, Train loss=0.3880, Valid loss=0.5932,Valid F1=0.4682,Valid ACC=0.8130, Valid weighted acc=0.5816\n",
      "08-08 01:55 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.711803674697876 seconds.\n",
      "08-08 01:55 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0002012350701528799\n",
      "08-08 01:56 [MainProcess, 13692] [INFO ]  Iteration:16, train loss = 0.370600 ,train F1 = 0.568561 ,train ACC = 0.879147 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 399.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:56 [MainProcess, 13692] [INFO ]  valid Epoch:16, Train loss=0.3706, Valid loss=0.6460,Valid F1=0.4465,Valid ACC=0.7559, Valid weighted acc=0.5980\n",
      "08-08 01:56 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.76673150062561 seconds.\n",
      "08-08 01:56 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.0001831239138391207\n",
      "08-08 01:56 [MainProcess, 13692] [INFO ]  Iteration:17, train loss = 0.353071 ,train F1 = 0.570181 ,train ACC = 0.879147 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 402.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:56 [MainProcess, 13692] [INFO ]  valid Epoch:17, Train loss=0.3531, Valid loss=0.6088,Valid F1=0.4614,Valid ACC=0.7876, Valid weighted acc=0.6013\n",
      "08-08 01:56 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.78504490852356 seconds.\n",
      "08-08 01:56 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00016664276159359984\n",
      "08-08 01:56 [MainProcess, 13692] [INFO ]  Iteration:18, train loss = 0.331002 ,train F1 = 0.577599 ,train ACC = 0.885071 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 403.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:56 [MainProcess, 13692] [INFO ]  valid Epoch:18, Train loss=0.3310, Valid loss=0.6103,Valid F1=0.4778,Valid ACC=0.8162, Valid weighted acc=0.5997\n",
      "08-08 01:56 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.765556573867798 seconds.\n",
      "08-08 01:56 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00015164491305017587\n",
      "08-08 01:57 [MainProcess, 13692] [INFO ]  Iteration:19, train loss = 0.307950 ,train F1 = 0.593165 ,train ACC = 0.893365 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 399.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:57 [MainProcess, 13692] [INFO ]  valid Epoch:19, Train loss=0.3080, Valid loss=0.6521,Valid F1=0.4762,Valid ACC=0.8130, Valid weighted acc=0.5980\n",
      "08-08 01:57 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.811449766159058 seconds.\n",
      "08-08 01:57 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00013799687087566004\n",
      "08-08 01:57 [MainProcess, 13692] [INFO ]  Iteration:20, train loss = 0.300036 ,train F1 = 0.604787 ,train ACC = 0.894550 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:57 [MainProcess, 13692] [INFO ]  valid Epoch:20, Train loss=0.3000, Valid loss=0.6817,Valid F1=0.4735,Valid ACC=0.8114, Valid weighted acc=0.5939\n",
      "08-08 01:57 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.835553646087646 seconds.\n",
      "08-08 01:57 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00012557715249685063\n",
      "08-08 01:57 [MainProcess, 13692] [INFO ]  Iteration:21, train loss = 0.293059 ,train F1 = 0.610673 ,train ACC = 0.899289 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 393.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:57 [MainProcess, 13692] [INFO ]  valid Epoch:21, Train loss=0.2931, Valid loss=0.6209,Valid F1=0.4674,Valid ACC=0.7924, Valid weighted acc=0.6103\n",
      "08-08 01:57 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.851903200149536 seconds.\n",
      "08-08 01:57 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00011427520877213407\n",
      "08-08 01:57 [MainProcess, 13692] [INFO ]  Iteration:22, train loss = 0.278421 ,train F1 = 0.619961 ,train ACC = 0.903633 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 399.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:58 [MainProcess, 13692] [INFO ]  valid Epoch:22, Train loss=0.2784, Valid loss=0.6558,Valid F1=0.4495,Valid ACC=0.7734, Valid weighted acc=0.5841\n",
      "08-08 01:58 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.86095356941223 seconds.\n",
      "08-08 01:58 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  0.00010399043998264201\n",
      "08-08 01:58 [MainProcess, 13692] [INFO ]  Iteration:23, train loss = 0.250606 ,train F1 = 0.623277 ,train ACC = 0.913507 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 401.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:58 [MainProcess, 13692] [INFO ]  valid Epoch:23, Train loss=0.2506, Valid loss=0.6637,Valid F1=0.4659,Valid ACC=0.7971, Valid weighted acc=0.5964\n",
      "08-08 01:58 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.826775789260864 seconds.\n",
      "08-08 01:58 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  9.463130038420423e-05\n",
      "08-08 01:58 [MainProcess, 13692] [INFO ]  Iteration:24, train loss = 0.233568 ,train F1 = 0.648912 ,train ACC = 0.919431 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 395.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:58 [MainProcess, 13692] [INFO ]  valid Epoch:24, Train loss=0.2336, Valid loss=0.6654,Valid F1=0.4648,Valid ACC=0.8019, Valid weighted acc=0.5890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:58 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.897164344787598 seconds.\n",
      "08-08 01:58 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  8.611448334962585e-05\n",
      "08-08 01:58 [MainProcess, 13692] [INFO ]  Iteration:25, train loss = 0.227636 ,train F1 = 0.658379 ,train ACC = 0.923381 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:58 [MainProcess, 13692] [INFO ]  valid Epoch:25, Train loss=0.2276, Valid loss=0.6481,Valid F1=0.4711,Valid ACC=0.7971, Valid weighted acc=0.6095\n",
      "08-08 01:58 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.884342670440674 seconds.\n",
      "08-08 01:58 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  7.836417984815953e-05\n",
      "08-08 01:59 [MainProcess, 13692] [INFO ]  Iteration:26, train loss = 0.212643 ,train F1 = 0.678232 ,train ACC = 0.930490 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 399.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:59 [MainProcess, 13692] [INFO ]  valid Epoch:26, Train loss=0.2126, Valid loss=0.7067,Valid F1=0.4692,Valid ACC=0.8082, Valid weighted acc=0.5890\n",
      "08-08 01:59 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.838884115219116 seconds.\n",
      "08-08 01:59 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  7.131140366182518e-05\n",
      "08-08 01:59 [MainProcess, 13692] [INFO ]  Iteration:27, train loss = 0.202768 ,train F1 = 0.664520 ,train ACC = 0.929305 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 401.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:59 [MainProcess, 13692] [INFO ]  valid Epoch:27, Train loss=0.2028, Valid loss=0.6575,Valid F1=0.4634,Valid ACC=0.7781, Valid weighted acc=0.6062\n",
      "08-08 01:59 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.81723690032959 seconds.\n",
      "08-08 01:59 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  6.489337733226091e-05\n",
      "08-08 01:59 [MainProcess, 13692] [INFO ]  Iteration:28, train loss = 0.185342 ,train F1 = 0.692537 ,train ACC = 0.939179 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 396.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 01:59 [MainProcess, 13692] [INFO ]  valid Epoch:28, Train loss=0.1853, Valid loss=0.6908,Valid F1=0.4541,Valid ACC=0.7797, Valid weighted acc=0.5906\n",
      "08-08 01:59 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.88973045349121 seconds.\n",
      "08-08 01:59 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  5.905297337235743e-05\n",
      "08-08 02:00 [MainProcess, 13692] [INFO ]  Iteration:29, train loss = 0.186644 ,train F1 = 0.702833 ,train ACC = 0.940758 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 392.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:00 [MainProcess, 13692] [INFO ]  valid Epoch:29, Train loss=0.1866, Valid loss=0.7135,Valid F1=0.4673,Valid ACC=0.8003, Valid weighted acc=0.5947\n",
      "08-08 02:00 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.904550075531006 seconds.\n",
      "08-08 02:00 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  5.373820576884526e-05\n",
      "08-08 02:00 [MainProcess, 13692] [INFO ]  Iteration:30, train loss = 0.176664 ,train F1 = 0.707047 ,train ACC = 0.937994 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:00 [MainProcess, 13692] [INFO ]  valid Epoch:30, Train loss=0.1767, Valid loss=0.7554,Valid F1=0.4707,Valid ACC=0.8130, Valid weighted acc=0.5849\n",
      "08-08 02:00 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.89922070503235 seconds.\n",
      "08-08 02:00 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  4.890176724964919e-05\n",
      "08-08 02:00 [MainProcess, 13692] [INFO ]  Iteration:31, train loss = 0.167086 ,train F1 = 0.711930 ,train ACC = 0.941943 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 403.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:00 [MainProcess, 13692] [INFO ]  valid Epoch:31, Train loss=0.1671, Valid loss=0.7101,Valid F1=0.4672,Valid ACC=0.7987, Valid weighted acc=0.5906\n",
      "08-08 02:00 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.829646587371826 seconds.\n",
      "08-08 02:00 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  4.450060819718076e-05\n",
      "08-08 02:01 [MainProcess, 13692] [INFO ]  Iteration:32, train loss = 0.162111 ,train F1 = 0.720772 ,train ACC = 0.943128 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 399.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:01 [MainProcess, 13692] [INFO ]  valid Epoch:32, Train loss=0.1621, Valid loss=0.7009,Valid F1=0.4553,Valid ACC=0.7655, Valid weighted acc=0.5997\n",
      "08-08 02:01 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.888092041015625 seconds.\n",
      "08-08 02:01 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  4.049555345943449e-05\n",
      "08-08 02:01 [MainProcess, 13692] [INFO ]  Iteration:33, train loss = 0.158810 ,train F1 = 0.746091 ,train ACC = 0.947077 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 399.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:01 [MainProcess, 13692] [INFO ]  valid Epoch:33, Train loss=0.1588, Valid loss=0.7543,Valid F1=0.4695,Valid ACC=0.8082, Valid weighted acc=0.5890\n",
      "08-08 02:01 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.872443437576294 seconds.\n",
      "08-08 02:01 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  3.685095364808539e-05\n",
      "08-08 02:01 [MainProcess, 13692] [INFO ]  Iteration:34, train loss = 0.156537 ,train F1 = 0.730148 ,train ACC = 0.948657 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 396.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:01 [MainProcess, 13692] [INFO ]  valid Epoch:34, Train loss=0.1565, Valid loss=0.7119,Valid F1=0.4597,Valid ACC=0.7940, Valid weighted acc=0.5849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:01 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.888655185699463 seconds.\n",
      "08-08 02:01 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  3.3534367819757705e-05\n",
      "08-08 02:02 [MainProcess, 13692] [INFO ]  Iteration:35, train loss = 0.147432 ,train F1 = 0.731281 ,train ACC = 0.949842 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 392.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:02 [MainProcess, 13692] [INFO ]  valid Epoch:35, Train loss=0.1474, Valid loss=0.7593,Valid F1=0.4651,Valid ACC=0.8067, Valid weighted acc=0.5816\n",
      "08-08 02:02 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.937631130218506 seconds.\n",
      "08-08 02:02 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  3.051627471597951e-05\n",
      "08-08 02:02 [MainProcess, 13692] [INFO ]  Iteration:36, train loss = 0.147460 ,train F1 = 0.729585 ,train ACC = 0.945103 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 392.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:02 [MainProcess, 13692] [INFO ]  valid Epoch:36, Train loss=0.1475, Valid loss=0.7178,Valid F1=0.4623,Valid ACC=0.7971, Valid weighted acc=0.5800\n",
      "08-08 02:02 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.91883087158203 seconds.\n",
      "08-08 02:02 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.7769809991541357e-05\n",
      "08-08 02:02 [MainProcess, 13692] [INFO ]  Iteration:37, train loss = 0.141282 ,train F1 = 0.766197 ,train ACC = 0.954186 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 399.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:02 [MainProcess, 13692] [INFO ]  valid Epoch:37, Train loss=0.1413, Valid loss=0.7272,Valid F1=0.4656,Valid ACC=0.8019, Valid weighted acc=0.5890\n",
      "08-08 02:02 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.90605878829956 seconds.\n",
      "08-08 02:02 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.5270527092302636e-05\n",
      "08-08 02:03 [MainProcess, 13692] [INFO ]  Iteration:38, train loss = 0.141173 ,train F1 = 0.753905 ,train ACC = 0.953791 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:03 [MainProcess, 13692] [INFO ]  valid Epoch:38, Train loss=0.1412, Valid loss=0.7291,Valid F1=0.4612,Valid ACC=0.7971, Valid weighted acc=0.5865\n",
      "08-08 02:03 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.889291048049927 seconds.\n",
      "08-08 02:03 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.29961796539954e-05\n",
      "08-08 02:03 [MainProcess, 13692] [INFO ]  Iteration:39, train loss = 0.158447 ,train F1 = 0.784344 ,train ACC = 0.956556 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 394.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:03 [MainProcess, 13692] [INFO ]  valid Epoch:39, Train loss=0.1584, Valid loss=0.7925,Valid F1=0.4635,Valid ACC=0.8067, Valid weighted acc=0.5783\n",
      "08-08 02:03 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.940407037734985 seconds.\n",
      "08-08 02:03 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.0926523485135813e-05\n",
      "08-08 02:03 [MainProcess, 13692] [INFO ]  Iteration:40, train loss = 0.136757 ,train F1 = 0.776170 ,train ACC = 0.956951 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 400.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:03 [MainProcess, 13692] [INFO ]  valid Epoch:40, Train loss=0.1368, Valid loss=0.7364,Valid F1=0.4697,Valid ACC=0.8051, Valid weighted acc=0.5906\n",
      "08-08 02:03 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.871684074401855 seconds.\n",
      "08-08 02:03 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.904313637147359e-05\n",
      "08-08 02:03 [MainProcess, 13692] [INFO ]  Iteration:41, train loss = 0.138928 ,train F1 = 0.799408 ,train ACC = 0.959321 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 395.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:03 [MainProcess, 13692] [INFO ]  valid Epoch:41, Train loss=0.1389, Valid loss=0.7597,Valid F1=0.4704,Valid ACC=0.8082, Valid weighted acc=0.5923\n",
      "08-08 02:03 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.91454839706421 seconds.\n",
      "08-08 02:03 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.7329254098040968e-05\n",
      "08-08 02:04 [MainProcess, 13692] [INFO ]  Iteration:42, train loss = 0.134723 ,train F1 = 0.800335 ,train ACC = 0.958136 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 393.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:04 [MainProcess, 13692] [INFO ]  valid Epoch:42, Train loss=0.1347, Valid loss=0.7475,Valid F1=0.4653,Valid ACC=0.8035, Valid weighted acc=0.5865\n",
      "08-08 02:04 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.91410541534424 seconds.\n",
      "08-08 02:04 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.5769621229217283e-05\n",
      "08-08 02:04 [MainProcess, 13692] [INFO ]  Iteration:43, train loss = 0.127357 ,train F1 = 0.797183 ,train ACC = 0.960111 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:04 [MainProcess, 13692] [INFO ]  valid Epoch:43, Train loss=0.1274, Valid loss=0.7774,Valid F1=0.4656,Valid ACC=0.8003, Valid weighted acc=0.5816\n",
      "08-08 02:04 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.93324089050293 seconds.\n",
      "08-08 02:04 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.4350355318587729e-05\n",
      "08-08 02:04 [MainProcess, 13692] [INFO ]  Iteration:44, train loss = 0.130199 ,train F1 = 0.786302 ,train ACC = 0.958136 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 393.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:04 [MainProcess, 13692] [INFO ]  valid Epoch:44, Train loss=0.1302, Valid loss=0.7823,Valid F1=0.4664,Valid ACC=0.8082, Valid weighted acc=0.5824\n",
      "08-08 02:04 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.874968767166138 seconds.\n",
      "08-08 02:04 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.3058823339914834e-05\n",
      "08-08 02:05 [MainProcess, 13692] [INFO ]  Iteration:45, train loss = 0.126044 ,train F1 = 0.788203 ,train ACC = 0.956951 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:05 [MainProcess, 13692] [INFO ]  valid Epoch:45, Train loss=0.1260, Valid loss=0.7512,Valid F1=0.4633,Valid ACC=0.7956, Valid weighted acc=0.5857\n",
      "08-08 02:05 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.88193702697754 seconds.\n",
      "08-08 02:05 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.18835292393225e-05\n",
      "08-08 02:05 [MainProcess, 13692] [INFO ]  Iteration:46, train loss = 0.127801 ,train F1 = 0.790088 ,train ACC = 0.957741 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 394.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:05 [MainProcess, 13692] [INFO ]  valid Epoch:46, Train loss=0.1278, Valid loss=0.7496,Valid F1=0.4681,Valid ACC=0.8019, Valid weighted acc=0.5890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:05 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.91689682006836 seconds.\n",
      "08-08 02:05 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.0814011607783475e-05\n",
      "08-08 02:05 [MainProcess, 13692] [INFO ]  Iteration:47, train loss = 0.122350 ,train F1 = 0.813010 ,train ACC = 0.961690 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 396.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:05 [MainProcess, 13692] [INFO ]  valid Epoch:47, Train loss=0.1223, Valid loss=0.7871,Valid F1=0.4658,Valid ACC=0.8082, Valid weighted acc=0.5824\n",
      "08-08 02:05 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.8861985206604 seconds.\n",
      "08-08 02:05 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  9.840750563082964e-06\n",
      "08-08 02:06 [MainProcess, 13692] [INFO ]  Iteration:48, train loss = 0.121923 ,train F1 = 0.792167 ,train ACC = 0.960111 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 397.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:06 [MainProcess, 13692] [INFO ]  valid Epoch:48, Train loss=0.1219, Valid loss=0.7753,Valid F1=0.4646,Valid ACC=0.8067, Valid weighted acc=0.5816\n",
      "08-08 02:06 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.91556191444397 seconds.\n",
      "08-08 02:06 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  8.955083012405497e-06\n",
      "08-08 02:06 [MainProcess, 13692] [INFO ]  Iteration:49, train loss = 0.120363 ,train F1 = 0.811816 ,train ACC = 0.962875 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 394.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:06 [MainProcess, 13692] [INFO ]  valid Epoch:49, Train loss=0.1204, Valid loss=0.7741,Valid F1=0.4635,Valid ACC=0.8019, Valid weighted acc=0.5792\n",
      "08-08 02:06 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.92919659614563 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:06 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  8.149125541289003e-06\n",
      "08-08 02:06 [MainProcess, 13692] [INFO ]  Iteration:50, train loss = 0.121680 ,train F1 = 0.817579 ,train ACC = 0.961690 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:06 [MainProcess, 13692] [INFO ]  valid Epoch:50, Train loss=0.1217, Valid loss=0.7596,Valid F1=0.4683,Valid ACC=0.8067, Valid weighted acc=0.5915\n",
      "08-08 02:06 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.915064811706543 seconds.\n",
      "08-08 02:06 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  7.415704242572993e-06\n",
      "08-08 02:07 [MainProcess, 13692] [INFO ]  Iteration:51, train loss = 0.122093 ,train F1 = 0.806422 ,train ACC = 0.960900 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 397.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:07 [MainProcess, 13692] [INFO ]  valid Epoch:51, Train loss=0.1221, Valid loss=0.8030,Valid F1=0.4623,Valid ACC=0.8051, Valid weighted acc=0.5775\n",
      "08-08 02:07 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.93314242362976 seconds.\n",
      "08-08 02:07 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  6.748290860741424e-06\n",
      "08-08 02:07 [MainProcess, 13692] [INFO ]  Iteration:52, train loss = 0.117345 ,train F1 = 0.810121 ,train ACC = 0.962085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 390.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:07 [MainProcess, 13692] [INFO ]  valid Epoch:52, Train loss=0.1173, Valid loss=0.7865,Valid F1=0.4649,Valid ACC=0.8082, Valid weighted acc=0.5824\n",
      "08-08 02:07 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.928760766983032 seconds.\n",
      "08-08 02:07 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  6.140944683274696e-06\n",
      "08-08 02:07 [MainProcess, 13692] [INFO ]  Iteration:53, train loss = 0.119885 ,train F1 = 0.807805 ,train ACC = 0.961690 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 387.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:07 [MainProcess, 13692] [INFO ]  valid Epoch:53, Train loss=0.1199, Valid loss=0.7668,Valid F1=0.4622,Valid ACC=0.8035, Valid weighted acc=0.5800\n",
      "08-08 02:07 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.920264959335327 seconds.\n",
      "08-08 02:07 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  5.588259661779973e-06\n",
      "08-08 02:08 [MainProcess, 13692] [INFO ]  Iteration:54, train loss = 0.114448 ,train F1 = 0.812137 ,train ACC = 0.962875 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 408.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:08 [MainProcess, 13692] [INFO ]  valid Epoch:54, Train loss=0.1144, Valid loss=0.7536,Valid F1=0.4655,Valid ACC=0.7987, Valid weighted acc=0.5906\n",
      "08-08 02:08 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.9240140914917 seconds.\n",
      "08-08 02:08 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  5.085316292219776e-06\n",
      "08-08 02:08 [MainProcess, 13692] [INFO ]  Iteration:55, train loss = 0.117723 ,train F1 = 0.818187 ,train ACC = 0.961690 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 405.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:08 [MainProcess, 13692] [INFO ]  valid Epoch:55, Train loss=0.1177, Valid loss=0.7672,Valid F1=0.4659,Valid ACC=0.8035, Valid weighted acc=0.5898\n",
      "08-08 02:08 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.63882541656494 seconds.\n",
      "08-08 02:08 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  4.627637825919996e-06\n",
      "08-08 02:08 [MainProcess, 13692] [INFO ]  Iteration:56, train loss = 0.112222 ,train F1 = 0.809132 ,train ACC = 0.960900 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 401.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:08 [MainProcess, 13692] [INFO ]  valid Epoch:56, Train loss=0.1122, Valid loss=0.7566,Valid F1=0.4668,Valid ACC=0.8035, Valid weighted acc=0.5898\n",
      "08-08 02:08 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.639744520187378 seconds.\n",
      "08-08 02:08 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  4.211150421587196e-06\n",
      "08-08 02:08 [MainProcess, 13692] [INFO ]  Iteration:57, train loss = 0.111679 ,train F1 = 0.810385 ,train ACC = 0.964060 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 395.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:09 [MainProcess, 13692] [INFO ]  valid Epoch:57, Train loss=0.1117, Valid loss=0.7700,Valid F1=0.4645,Valid ACC=0.7971, Valid weighted acc=0.5865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:09 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.691044807434082 seconds.\n",
      "08-08 02:09 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  3.832146883644349e-06\n",
      "08-08 02:09 [MainProcess, 13692] [INFO ]  Iteration:58, train loss = 0.110993 ,train F1 = 0.825901 ,train ACC = 0.964060 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:09 [MainProcess, 13692] [INFO ]  valid Epoch:58, Train loss=0.1110, Valid loss=0.7955,Valid F1=0.4635,Valid ACC=0.8067, Valid weighted acc=0.5783\n",
      "08-08 02:09 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.668240308761597 seconds.\n",
      "08-08 02:09 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  3.487253664116358e-06\n",
      "08-08 02:09 [MainProcess, 13692] [INFO ]  Iteration:59, train loss = 0.112080 ,train F1 = 0.824052 ,train ACC = 0.964455 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 397.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:09 [MainProcess, 13692] [INFO ]  valid Epoch:59, Train loss=0.1121, Valid loss=0.7707,Valid F1=0.4665,Valid ACC=0.7987, Valid weighted acc=0.5874\n",
      "08-08 02:09 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.66214895248413 seconds.\n",
      "08-08 02:09 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  3.1734008343458857e-06\n",
      "08-08 02:09 [MainProcess, 13692] [INFO ]  Iteration:60, train loss = 0.112041 ,train F1 = 0.811034 ,train ACC = 0.962875 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 403.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:09 [MainProcess, 13692] [INFO ]  valid Epoch:60, Train loss=0.1120, Valid loss=0.7569,Valid F1=0.4624,Valid ACC=0.7924, Valid weighted acc=0.5874\n",
      "08-08 02:09 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.726466417312622 seconds.\n",
      "08-08 02:09 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.887794759254756e-06\n",
      "08-08 02:10 [MainProcess, 13692] [INFO ]  Iteration:61, train loss = 0.115721 ,train F1 = 0.801137 ,train ACC = 0.960900 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 396.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:10 [MainProcess, 13692] [INFO ]  valid Epoch:61, Train loss=0.1157, Valid loss=0.7922,Valid F1=0.4630,Valid ACC=0.8035, Valid weighted acc=0.5800\n",
      "08-08 02:10 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.7363064289093 seconds.\n",
      "08-08 02:10 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.627893230921828e-06\n",
      "08-08 02:10 [MainProcess, 13692] [INFO ]  Iteration:62, train loss = 0.111717 ,train F1 = 0.825558 ,train ACC = 0.963270 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 401.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:10 [MainProcess, 13692] [INFO ]  valid Epoch:62, Train loss=0.1117, Valid loss=0.7594,Valid F1=0.4620,Valid ACC=0.7908, Valid weighted acc=0.5865\n",
      "08-08 02:10 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.714155673980713 seconds.\n",
      "08-08 02:10 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.3913828401388635e-06\n",
      "08-08 02:10 [MainProcess, 13692] [INFO ]  Iteration:63, train loss = 0.132029 ,train F1 = 0.811198 ,train ACC = 0.960111 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 400.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:10 [MainProcess, 13692] [INFO ]  valid Epoch:63, Train loss=0.1320, Valid loss=0.8112,Valid F1=0.4648,Valid ACC=0.8082, Valid weighted acc=0.5792\n",
      "08-08 02:10 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.697500705718994 seconds.\n",
      "08-08 02:10 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  2.176158384526366e-06\n",
      "08-08 02:11 [MainProcess, 13692] [INFO ]  Iteration:64, train loss = 0.111530 ,train F1 = 0.826594 ,train ACC = 0.964455 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 399.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:11 [MainProcess, 13692] [INFO ]  valid Epoch:64, Train loss=0.1115, Valid loss=0.8151,Valid F1=0.4664,Valid ACC=0.8082, Valid weighted acc=0.5824\n",
      "08-08 02:11 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.704752922058105 seconds.\n",
      "08-08 02:11 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.980304129918993e-06\n",
      "08-08 02:11 [MainProcess, 13692] [INFO ]  Iteration:65, train loss = 0.114527 ,train F1 = 0.830096 ,train ACC = 0.965245 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 404.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:11 [MainProcess, 13692] [INFO ]  valid Epoch:65, Train loss=0.1145, Valid loss=0.8072,Valid F1=0.4660,Valid ACC=0.8098, Valid weighted acc=0.5800\n",
      "08-08 02:11 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.64708399772644 seconds.\n",
      "08-08 02:11 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.8020767582262836e-06\n",
      "08-08 02:11 [MainProcess, 13692] [INFO ]  Iteration:66, train loss = 0.108617 ,train F1 = 0.818864 ,train ACC = 0.964455 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 406.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:11 [MainProcess, 13692] [INFO ]  valid Epoch:66, Train loss=0.1086, Valid loss=0.7771,Valid F1=0.4665,Valid ACC=0.7987, Valid weighted acc=0.5874\n",
      "08-08 02:11 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.654106616973877 seconds.\n",
      "08-08 02:11 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.639889849985918e-06\n",
      "08-08 02:12 [MainProcess, 13692] [INFO ]  Iteration:67, train loss = 0.110046 ,train F1 = 0.826072 ,train ACC = 0.964455 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 404.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:12 [MainProcess, 13692] [INFO ]  valid Epoch:67, Train loss=0.1100, Valid loss=0.7757,Valid F1=0.4638,Valid ACC=0.7971, Valid weighted acc=0.5833\n",
      "08-08 02:12 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.681878089904785 seconds.\n",
      "08-08 02:12 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.4922997634871856e-06\n",
      "08-08 02:12 [MainProcess, 13692] [INFO ]  Iteration:68, train loss = 0.111013 ,train F1 = 0.835487 ,train ACC = 0.966035 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 401.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:12 [MainProcess, 13692] [INFO ]  valid Epoch:68, Train loss=0.1110, Valid loss=0.7845,Valid F1=0.4661,Valid ACC=0.8035, Valid weighted acc=0.5865\n",
      "08-08 02:12 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.680997371673584 seconds.\n",
      "08-08 02:12 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.357992784773339e-06\n",
      "08-08 02:12 [MainProcess, 13692] [INFO ]  Iteration:69, train loss = 0.115000 ,train F1 = 0.820784 ,train ACC = 0.964060 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:12 [MainProcess, 13692] [INFO ]  valid Epoch:69, Train loss=0.1150, Valid loss=0.8114,Valid F1=0.4631,Valid ACC=0.8082, Valid weighted acc=0.5759\n",
      "08-08 02:12 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.713639974594116 seconds.\n",
      "08-08 02:12 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.2357734341437386e-06\n",
      "08-08 02:13 [MainProcess, 13692] [INFO ]  Iteration:70, train loss = 0.114820 ,train F1 = 0.823189 ,train ACC = 0.963665 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 403.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:13 [MainProcess, 13692] [INFO ]  valid Epoch:70, Train loss=0.1148, Valid loss=0.7890,Valid F1=0.4614,Valid ACC=0.8003, Valid weighted acc=0.5783\n",
      "08-08 02:13 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.6570885181427 seconds.\n",
      "08-08 02:13 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.1245538250708021e-06\n",
      "08-08 02:13 [MainProcess, 13692] [INFO ]  Iteration:71, train loss = 0.109395 ,train F1 = 0.823883 ,train ACC = 0.964060 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:13 [MainProcess, 13692] [INFO ]  valid Epoch:71, Train loss=0.1094, Valid loss=0.7914,Valid F1=0.4651,Valid ACC=0.8019, Valid weighted acc=0.5824\n",
      "08-08 02:13 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.7170729637146 seconds.\n",
      "08-08 02:13 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  1.02334398081443e-06\n",
      "08-08 02:13 [MainProcess, 13692] [INFO ]  Iteration:72, train loss = 0.107895 ,train F1 = 0.834566 ,train ACC = 0.966825 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 396.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:13 [MainProcess, 13692] [INFO ]  valid Epoch:72, Train loss=0.1079, Valid loss=0.7811,Valid F1=0.4670,Valid ACC=0.8035, Valid weighted acc=0.5865\n",
      "08-08 02:13 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.70676040649414 seconds.\n",
      "08-08 02:13 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  9.312430225411312e-07\n",
      "08-08 02:13 [MainProcess, 13692] [INFO ]  Iteration:73, train loss = 0.110010 ,train F1 = 0.829965 ,train ACC = 0.965245 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:13 [MainProcess, 13692] [INFO ]  valid Epoch:73, Train loss=0.1100, Valid loss=0.7821,Valid F1=0.4638,Valid ACC=0.7971, Valid weighted acc=0.5833\n",
      "08-08 02:13 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.7261860370636 seconds.\n",
      "08-08 02:13 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  8.474311505124295e-07\n",
      "08-08 02:14 [MainProcess, 13692] [INFO ]  Iteration:74, train loss = 0.107270 ,train F1 = 0.830564 ,train ACC = 0.966035 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 397.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:14 [MainProcess, 13692] [INFO ]  valid Epoch:74, Train loss=0.1073, Valid loss=0.7851,Valid F1=0.4678,Valid ACC=0.8003, Valid weighted acc=0.5882\n",
      "08-08 02:14 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.715025901794434 seconds.\n",
      "08-08 02:14 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  7.711623469663109e-07\n",
      "08-08 02:14 [MainProcess, 13692] [INFO ]  Iteration:75, train loss = 0.109650 ,train F1 = 0.823360 ,train ACC = 0.964060 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 400.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:14 [MainProcess, 13692] [INFO ]  valid Epoch:75, Train loss=0.1096, Valid loss=0.7806,Valid F1=0.4649,Valid ACC=0.8051, Valid weighted acc=0.5841\n",
      "08-08 02:14 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.69009780883789 seconds.\n",
      "08-08 02:14 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  7.017577357393429e-07\n",
      "08-08 02:14 [MainProcess, 13692] [INFO ]  Iteration:76, train loss = 0.108722 ,train F1 = 0.833042 ,train ACC = 0.966035 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 401.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:14 [MainProcess, 13692] [INFO ]  valid Epoch:76, Train loss=0.1087, Valid loss=0.7988,Valid F1=0.4649,Valid ACC=0.8019, Valid weighted acc=0.5792\n",
      "08-08 02:14 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.725768089294434 seconds.\n",
      "08-08 02:14 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  6.38599539522802e-07\n",
      "08-08 02:15 [MainProcess, 13692] [INFO ]  Iteration:77, train loss = 0.110952 ,train F1 = 0.805258 ,train ACC = 0.962085 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 398.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:15 [MainProcess, 13692] [INFO ]  valid Epoch:77, Train loss=0.1110, Valid loss=0.8006,Valid F1=0.4660,Valid ACC=0.8067, Valid weighted acc=0.5816\n",
      "08-08 02:15 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.737171411514282 seconds.\n",
      "08-08 02:15 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  5.811255809657499e-07\n",
      "08-08 02:15 [MainProcess, 13692] [INFO ]  Iteration:78, train loss = 0.156624 ,train F1 = 0.822928 ,train ACC = 0.963665 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 402.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:15 [MainProcess, 13692] [INFO ]  valid Epoch:78, Train loss=0.1566, Valid loss=0.8356,Valid F1=0.4620,Valid ACC=0.8082, Valid weighted acc=0.5726\n",
      "08-08 02:15 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.688886165618896 seconds.\n",
      "08-08 02:15 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 80/80 [00:17<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr:  5.288242786788324e-07\n",
      "08-08 02:15 [MainProcess, 13692] [INFO ]  Iteration:79, train loss = 0.109650 ,train F1 = 0.819042 ,train ACC = 0.964060 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|████████████████████████████████████████| 631/631 [00:01<00:00, 393.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08-08 02:15 [MainProcess, 13692] [INFO ]  valid Epoch:79, Train loss=0.1096, Valid loss=0.7656,Valid F1=0.4617,Valid ACC=0.7924, Valid weighted acc=0.5841\n",
      "08-08 02:15 [MainProcess, 13692] [INFO ]  Time used for each epoch training: 18.73727774620056 seconds.\n",
      "08-08 02:15 [MainProcess, 13692] [INFO ]  **************************************************\n"
     ]
    }
   ],
   "source": [
    "# # Find data files.\n",
    "# if verbose >= 1:\n",
    "#     print('Finding data files...')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print ('Available devices ', torch.cuda.device_count())\n",
    "    \n",
    "# GPU_NUM = args.gpu # 원하는 GPU 번호 입력\n",
    "# device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.cuda.set_device(device) # change allocation of current GPU\n",
    "\n",
    "# # Find the patient data files.\n",
    "# patient_files = find_patient_files(args.train_data_folder)\n",
    "# num_patient_files = len(patient_files)\n",
    "\n",
    "# if num_patient_files==0:\n",
    "#     raise Exception('No data was provided.')\n",
    "\n",
    "# # Create a folder for the model if it does not already exist.\n",
    "# os.makedirs(args.model_path, exist_ok=True)\n",
    "# os.makedirs(args.logdir, exist_ok=True)\n",
    "\n",
    "# open(args.logdir + 'score.txt', \"a+\")\n",
    "# score_file = open(args.logdir + 'score.txt', \"a+\")\n",
    "\n",
    "\n",
    "# model_folder = args.model_path\n",
    "# log_dir = args.logdir\n",
    "# logger = get_logger(log_dir + '/' + model_folder)\n",
    "\n",
    "# # Define the model\n",
    "# lcnn_model = LCNN(\"murmur\")\n",
    "# lcnn_model = lcnn_model.cuda(device)\n",
    "\n",
    "# # Define the metrics\n",
    "# accuracy = Accuracy(num_classes=3, multiclass=True)\n",
    "# f1 = F1(num_classes=3,average='macro', multiclass=True)\n",
    "\n",
    "# # optimizer, loss\n",
    "# opt = torch.optim.Adam(lcnn_model.parameters(), lr=args.lr, betas=(0.9, 0.999))\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(opt, 0.91)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# #data loader\n",
    "# trainset = train_loader(args.train_data_folder)\n",
    "# validset = train_loader(args.valid_data_folder)\n",
    "# point_sampler = RandomSampler(trainset)\n",
    "\n",
    "# dataloader_train = DataLoader(dataset=trainset,\n",
    "#                     batch_size=args.minibatchsize_train,\n",
    "#                            sampler =point_sampler,\n",
    "#                            num_workers=args.train_num_workers)\n",
    "# dataloader_valid = DataLoader(dataset=validset,\n",
    "#                     batch_size=args.minibatchsize_valid,\n",
    "#                            num_workers=args.dev_num_workers)\n",
    "\n",
    "# Train the model.\n",
    "# if verbose >= 1:\n",
    "#     print('Training model...')\n",
    "    \n",
    "murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "outcome_classes = ['Abnormal', 'Normal']\n",
    "if args.mode=='murmur':\n",
    "    classes =  murmur_classes \n",
    "elif args.mode =='outcome':\n",
    "    classes = outcome_classes\n",
    "\n",
    "\n",
    "    \n",
    "all_file_train = len(trainset)\n",
    "dataloader_train_len = len(dataloader_train)\n",
    "output_preds_labels_train = torch.empty((all_file_train,))\n",
    "output_preds_probs_train = torch.empty((all_file_train,3))\n",
    "output_gt_labels_train = torch.empty((all_file_train,))\n",
    "\n",
    "for iter_ in range(args.end_iter):\n",
    "    start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    idx = 0\n",
    "    lcnn_model.train()\n",
    "    for feature, current_murmur, current_outcome in tqdm(dataloader_train):\n",
    "        feature = feature.cuda()\n",
    "#         current_age_group = current_age_group.cuda()\n",
    "#         sex_feature = sex_feature.cuda()\n",
    "#         height_weight = height_weight.cuda()\n",
    "#         preg_feature = preg_feature.cuda()\n",
    "#         loc_feature = loc_feature.cuda()\n",
    "        current_murmur = current_murmur.cuda()\n",
    "        current_outcome = current_outcome.cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        output_train = lcnn_model(feature)\n",
    "        loss = criterion(output_train, current_murmur)\n",
    "\n",
    "\n",
    "\n",
    "        output_probs_train = F.log_softmax(output_train, dim=1)\n",
    "\n",
    "        _, output_label_argmax = torch.max(output_probs_train, dim=1)\n",
    "\n",
    "\n",
    "        output_label_argmax = output_label_argmax.data.detach().cpu()\n",
    "\n",
    "        output_preds_labels_train[idx*args.minibatchsize_train:(idx+1)*args.minibatchsize_train]= output_label_argmax  #murmur 예측 레이블 (0,1,2)\n",
    "\n",
    "        output_preds_probs_train[idx*args.minibatchsize_train:(idx+1)*args.minibatchsize_train,:] = output_probs_train\n",
    "        \n",
    "        \n",
    "\n",
    "        _, murmur_label_argmax = torch.max(current_murmur.data, dim=1)  #murmur groud truth (0,1,2)\n",
    "\n",
    "        output_gt_labels_train[idx*args.minibatchsize_train:(idx+1)*args.minibatchsize_train] = murmur_label_argmax.data.detach().cpu()\n",
    "\n",
    "\n",
    "\n",
    "        idx +=1              \n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_f1 = f1(preds = torch.tensor(output_preds_labels_train, dtype=torch.int32), target = torch.tensor(output_gt_labels_train, dtype=torch.int32))\n",
    "    train_acc = accuracy(preds = torch.tensor(output_preds_labels_train, dtype=torch.int32), target = torch.tensor(output_gt_labels_train, dtype=torch.int32))\n",
    "    \n",
    "\n",
    "    scheduler.step()\n",
    "    print(\"lr: \", opt.param_groups[0]['lr'])\n",
    "    logger.info(\"Iteration:{0}, train loss = {1:.6f} ,train F1 = {2:.6f} ,train ACC = {3:.6f} \".format(iter_, \n",
    "                 running_loss/dataloader_train_len,train_f1,train_acc))\n",
    "\n",
    "    # eval\n",
    "    all_file_valid = len(validset)\n",
    "    dataloader_valid_len = len(dataloader_valid)\n",
    "    lcnn_model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        running_loss_dev = 0.0\n",
    "        index = 0\n",
    "        output_preds_labels_dev = torch.empty((all_file_valid,))\n",
    "        output_preds_labels_onehot_dev = torch.zeros((all_file_valid,3))\n",
    "        output_preds_probs_dev = torch.empty((all_file_valid,3))\n",
    "        output_gt_labels_dev= torch.empty((all_file_valid,))\n",
    "        output_gt_labels_onehot_dev = torch.empty((all_file_valid,3))\n",
    "        for feature,  current_murmur, current_outcome in tqdm(dataloader_valid):\n",
    "            feature_dev = feature.cuda()\n",
    "#             current_age_group_dev = current_age_group.cuda()\n",
    "#             sex_feature_dev = sex_feature.cuda()\n",
    "#             height_weight_dev = height_weight.cuda()\n",
    "#             preg_feature_dev = preg_feature.cuda()\n",
    "#             loc_feature_dev = loc_feature.cuda()\n",
    "            current_murmur_dev = current_murmur.cuda()\n",
    "            current_outcome_dev = current_outcome.cuda()\n",
    "\n",
    "\n",
    "            output_dev = lcnn_model(feature_dev)\n",
    "            loss_dev = criterion(output_dev, current_murmur_dev)                   \n",
    "            running_loss_dev += loss_dev.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            output_probs_dev = F.log_softmax(output_dev, dim=1)\n",
    "\n",
    "            _, output_label_argmax_dev = torch.max(output_probs_dev, dim=1)\n",
    "            \n",
    "            output_preds_labels_onehot_dev[index,output_label_argmax_dev]=1\n",
    "\n",
    "\n",
    "            output_label_argmax_dev = output_label_argmax_dev.data.detach().cpu()\n",
    "\n",
    "            output_preds_labels_dev[index*args.minibatchsize_valid:(index+1)*args.minibatchsize_valid]= output_label_argmax_dev  #murmur 예측 레이블 (0,1,2)\n",
    "\n",
    "            output_preds_probs_dev[index*args.minibatchsize_valid:(index+1)*args.minibatchsize_valid,:] = output_probs_dev\n",
    "\n",
    "            _, murmur_label_argmax_dev = torch.max(current_murmur_dev.data, dim=1)  #murmur groud truth (0,1,2)\n",
    "\n",
    "            output_gt_labels_dev[index*args.minibatchsize_valid:(index+1)*args.minibatchsize_valid] = murmur_label_argmax_dev\n",
    "            \n",
    "            output_gt_labels_onehot_dev[index*args.minibatchsize_valid:(index+1)*args.minibatchsize_valid] = current_murmur_dev\n",
    "\n",
    "            index = index+1   \n",
    "            \n",
    "        \n",
    "        \n",
    "        outputs = output_preds_labels_onehot_dev.data.detach().cpu().numpy()\n",
    "        labels = output_gt_labels_onehot_dev.data.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "        dev_f1 = f1(preds = torch.tensor(output_preds_labels_dev, dtype=torch.int32), target = torch.tensor(output_gt_labels_dev, dtype=torch.int32))\n",
    "        dev_acc = accuracy(preds = torch.tensor(output_preds_labels_dev, dtype=torch.int32),target =  torch.tensor(output_gt_labels_dev, dtype=torch.int32))\n",
    "        weighted_acc = compute_weighted_accuracy(labels, outputs, classes)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    logger.info(\"valid Epoch:%d, Train loss=%.4f, Valid loss=%.4f,Valid F1=%.4f,Valid ACC=%.4f, Valid weighted acc=%.4f\" %( iter_,\n",
    "            running_loss/dataloader_train_len, running_loss_dev/dataloader_valid_len, dev_f1, dev_acc,weighted_acc ))\n",
    "    score_file.write(\"%d epoch, VALID LOSS %f, VALID F1 %2.2f%% VALID ACC %2.2f%% VALID WEIGHTED ACC%2.2f%%\\n\"%(iter_, \n",
    "                            running_loss_dev/dataloader_valid_len, dev_f1, dev_acc,weighted_acc ))\n",
    "    score_file.flush()\n",
    "\n",
    "    torch.save(lcnn_model.state_dict(), os.path.join(model_folder, \"{}_{}.model\".format(args.model_name, iter_)))\n",
    "\n",
    "    end_time = time.time()\n",
    "    logger.info(\"Time used for each epoch training: {} seconds.\".format(end_time - start_time))\n",
    "    logger.info(\"*\" * 50)\n",
    "\n",
    "\n",
    "# if verbose >= 1:\n",
    "#     print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1efe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_challenge_model(model_folder, verbose):\n",
    "    murmur_train_model = torch.load(model_folder + '/' + args.model_name + '_63.model')\n",
    "    outcome_train_model = torch.load(model_folder + '/' + args.outcome_model_name + '_63.model')\n",
    "    return murmur_train_model, outcome_train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01093012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_challenge_model(model_folder, verbose):\n",
    "    murmur_train_model = torch.load('/home/jh20/narin/physionet/hmd_LCNN' + '/' + 'hmd_LCNN_model_murmur_.model')\n",
    "    outcome_train_model = torch.load('/home/jh20/narin/physionet/hmd_CNN_outcome' + '/' + 'hmd_CNN_outcome_model_25.model')\n",
    "    return [murmur_train_model, outcome_train_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a02ee7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_challenge_model(args.model_path, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4bcdcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/jh20/narin/physionet/python-classifier-2022/model\")\n",
    "\n",
    "from CNN_outcome import CNN as CNN_outcome\n",
    "from LCNN_murmur import LCNN as LCNN_murmur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "867c3044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_challenge_model(model, data, recordings, verbose):\n",
    "    murmur_model , outcome_model = model\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#     print ('Available devices ', torch.cuda.device_count())\n",
    "        \n",
    "    GPU_NUM = args.gpu # 원하는 GPU 번호 입력\n",
    "    device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.set_device(device) # change allocation of current GPU\n",
    "\n",
    "    \n",
    "    # Define the model\n",
    "    murmur_classifier = LCNN_murmur(\"murmur\")\n",
    "    murmur_classifier = murmur_classifier.cuda(device)\n",
    "    \n",
    "    outcome_classifier = CNN_outcome()\n",
    "    outcome_classifier = outcome_classifier.cuda(device)\n",
    "    \n",
    "    murmur_classifier.load_state_dict(murmur_model)\n",
    "    outcome_classifier.load_state_dict(outcome_model)\n",
    "    \n",
    "#     wav_files = glob.glob(data_folder + '*.wav')\n",
    "#     num_wav_files = len(wav_files)\n",
    "    \n",
    "    murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "    num_murmur_classes = len(murmur_classes)\n",
    "    outcome_classes = ['Abnormal', 'Normal']\n",
    "    num_outcome_classes = len(outcome_classes)\n",
    "    \n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "    \n",
    "    num_recordings = len(recordings)\n",
    "    recordings_list=[]\n",
    "    for i in range(num_recordings):\n",
    "        recording = recordings[i]\n",
    "        length = 20*4000  \n",
    "        if recording.shape[0] <= length:\n",
    "            shortage = length - recording.shape[0]\n",
    "            recording = np.pad(recording, (0, shortage), 'wrap')\n",
    "        start_frame = np.int64(random.random()*(recording.shape[0]-length))\n",
    "        recording = recording[start_frame:start_frame + length] \n",
    "        \n",
    "        recordings_list.append(recording)\n",
    "        \n",
    "\n",
    "    features = get_features(data, recordings_list)\n",
    "    \n",
    "    predict_murmur_arr= np.zeros((num_recordings,3))\n",
    "    predict_outcome_arr= np.zeros((num_recordings,2))\n",
    "    \n",
    "    for i in range(num_recordings):\n",
    "        \n",
    "        logmel = torch.tensor(features['mel'][i]).cuda()\n",
    "        age = torch.tensor(features['age']).cuda()\n",
    "        sex = torch.tensor(features['sex']).cuda()\n",
    "        hw = torch.tensor(features['hw']).cuda()\n",
    "        preg = torch.tensor(features['preg']).cuda()\n",
    "        loc = torch.tensor(features['loc'][i]).cuda()\n",
    "        wav2vec2_feature = torch.tensor(features['wav2vec2'][i]).cuda()\n",
    "        \n",
    "        logmel = logmel.unsqueeze(0)\n",
    "        age = age.unsqueeze(0)\n",
    "        sex = sex.unsqueeze(0)\n",
    "        hw = hw.unsqueeze(0)\n",
    "        preg = preg.unsqueeze(0)\n",
    "        loc = loc.unsqueeze(0)\n",
    "        wav2vec2_feature = wav2vec2_feature.unsqueeze(1)\n",
    "        \n",
    "        predict_murmur = F.log_softmax(murmur_classifier(wav2vec2_feature), dim=1)\n",
    "        predict_outcome = F.log_softmax(outcome_classifier(logmel,age,sex,hw,preg,loc), dim=1)\n",
    "        \n",
    "        predict_murmur_arr[i,:]= predict_murmur.data.detach().cpu().numpy()\n",
    "        predict_outcome_arr[i,:] = predict_outcome.data.detach().cpu().numpy()\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    # Get classifier probabilities.\n",
    "    idx1 = predict_murmur_arr.argmax(axis=0)[0]\n",
    "    murmur_probabilities = predict_murmur_arr[idx1,] \n",
    "    idx2 = predict_outcome_arr.argmax(axis=0)[0]\n",
    "    outcome_probabilities = predict_outcome_arr[idx2,]\n",
    "\n",
    "\n",
    "    # Choose label with highest probability.\n",
    "    murmur_labels = np.zeros(len(murmur_classes), dtype=np.int_)\n",
    "    idx = np.argmax(murmur_probabilities)\n",
    "    murmur_labels[idx] = 1\n",
    "    outcome_labels = np.zeros(len(outcome_classes), dtype=np.int_)\n",
    "    idx = np.argmax(outcome_probabilities)\n",
    "    outcome_labels[idx] = 1\n",
    "\n",
    "    # Concatenate classes, labels, and probabilities.\n",
    "    classes = murmur_classes + outcome_classes\n",
    "    labels = np.concatenate((murmur_labels, outcome_labels))\n",
    "    probabilities = np.concatenate((murmur_probabilities, outcome_probabilities))\n",
    "\n",
    "    return classes, labels, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0d2ab94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Present', 'Unknown', 'Absent', 'Abnormal', 'Normal'],\n",
       " array([0, 0, 1, 1, 0]),\n",
       " array([-2.87280416, -3.26627851, -0.099476  , -0.41523492, -1.07935441]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_challenge_model(model, patient_data, recordings_list, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6573f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os, sys\n",
    "# from helper_code import *\n",
    "# from team_code import load_challenge_model, run_challenge_model\n",
    "\n",
    "# Run model.\n",
    "def run_model(model_folder, data_folder, output_folder, allow_failures, verbose):\n",
    "    # Load models.\n",
    "    if verbose >= 1:\n",
    "        print('Loading Challenge model...')\n",
    "\n",
    "    model = load_challenge_model(model_folder, verbose) ### Teams: Implement this function!!!\n",
    "\n",
    "    # Find the patient data files.\n",
    "    patient_files = find_patient_files(data_folder)\n",
    "    num_patient_files = len(patient_files)\n",
    "\n",
    "    if num_patient_files==0:\n",
    "        raise Exception('No data was provided.')\n",
    "\n",
    "    # Create a folder for the Challenge outputs if it does not already exist.\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Run the team's model on the Challenge data.\n",
    "    if verbose >= 1:\n",
    "        print('Running model on Challenge data...')\n",
    "\n",
    "    # Iterate over the patient files.\n",
    "    for i in range(num_patient_files):\n",
    "        if verbose >= 2:\n",
    "            print('    {}/{}...'.format(i+1, num_patient_files))\n",
    "\n",
    "        patient_data = load_patient_data(patient_files[i])\n",
    "        recordings = load_recordings(data_folder, patient_data)\n",
    "\n",
    "        # Allow or disallow the model to fail on parts of the data; helpful for debugging.\n",
    "        try:\n",
    "            classes, labels, probabilities = run_challenge_model(model, patient_data, recordings, verbose) ### Teams: Implement this function!!!\n",
    "        except:\n",
    "            if allow_failures:\n",
    "                if verbose >= 2:\n",
    "                    print('... failed.')\n",
    "                classes, labels, probabilities = list(), list(), list()\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        # Save Challenge outputs.\n",
    "        head, tail = os.path.split(patient_files[i])\n",
    "        root, extension = os.path.splitext(tail)\n",
    "        output_file = os.path.join(output_folder, root + '.csv')\n",
    "        patient_id = get_patient_id(patient_data)\n",
    "        save_challenge_outputs(output_file, patient_id, classes, labels, probabilities)\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80ac5c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Challenge model...\n",
      "Running model on Challenge data...\n",
      "    1/191...\n",
      "    2/191...\n",
      "    3/191...\n",
      "    4/191...\n",
      "    5/191...\n",
      "    6/191...\n",
      "    7/191...\n",
      "    8/191...\n",
      "    9/191...\n",
      "    10/191...\n",
      "    11/191...\n",
      "    12/191...\n",
      "    13/191...\n",
      "    14/191...\n",
      "    15/191...\n",
      "    16/191...\n",
      "    17/191...\n",
      "    18/191...\n",
      "    19/191...\n",
      "    20/191...\n",
      "    21/191...\n",
      "    22/191...\n",
      "    23/191...\n",
      "    24/191...\n",
      "    25/191...\n",
      "    26/191...\n",
      "    27/191...\n",
      "    28/191...\n",
      "    29/191...\n",
      "    30/191...\n",
      "    31/191...\n",
      "    32/191...\n",
      "    33/191...\n",
      "    34/191...\n",
      "    35/191...\n",
      "    36/191...\n",
      "    37/191...\n",
      "    38/191...\n",
      "    39/191...\n",
      "    40/191...\n",
      "    41/191...\n",
      "    42/191...\n",
      "    43/191...\n",
      "    44/191...\n",
      "    45/191...\n",
      "    46/191...\n",
      "    47/191...\n",
      "    48/191...\n",
      "    49/191...\n",
      "    50/191...\n",
      "    51/191...\n",
      "    52/191...\n",
      "    53/191...\n",
      "    54/191...\n",
      "    55/191...\n",
      "    56/191...\n",
      "    57/191...\n",
      "    58/191...\n",
      "    59/191...\n",
      "    60/191...\n",
      "    61/191...\n",
      "    62/191...\n",
      "    63/191...\n",
      "    64/191...\n",
      "    65/191...\n",
      "    66/191...\n",
      "    67/191...\n",
      "    68/191...\n",
      "    69/191...\n",
      "    70/191...\n",
      "    71/191...\n",
      "    72/191...\n",
      "    73/191...\n",
      "    74/191...\n",
      "    75/191...\n",
      "    76/191...\n",
      "    77/191...\n",
      "    78/191...\n",
      "    79/191...\n",
      "    80/191...\n",
      "    81/191...\n",
      "    82/191...\n",
      "    83/191...\n",
      "    84/191...\n",
      "    85/191...\n",
      "    86/191...\n",
      "    87/191...\n",
      "    88/191...\n",
      "    89/191...\n",
      "    90/191...\n",
      "    91/191...\n",
      "    92/191...\n",
      "    93/191...\n",
      "    94/191...\n",
      "    95/191...\n",
      "    96/191...\n",
      "    97/191...\n",
      "    98/191...\n",
      "    99/191...\n",
      "    100/191...\n",
      "    101/191...\n",
      "    102/191...\n",
      "    103/191...\n",
      "    104/191...\n",
      "    105/191...\n",
      "    106/191...\n",
      "    107/191...\n",
      "    108/191...\n",
      "    109/191...\n",
      "    110/191...\n",
      "    111/191...\n",
      "    112/191...\n",
      "    113/191...\n",
      "    114/191...\n",
      "    115/191...\n",
      "    116/191...\n",
      "    117/191...\n",
      "    118/191...\n",
      "    119/191...\n",
      "    120/191...\n",
      "    121/191...\n",
      "    122/191...\n",
      "    123/191...\n",
      "    124/191...\n",
      "    125/191...\n",
      "    126/191...\n",
      "    127/191...\n",
      "    128/191...\n",
      "    129/191...\n",
      "    130/191...\n",
      "    131/191...\n",
      "    132/191...\n",
      "    133/191...\n",
      "    134/191...\n",
      "    135/191...\n",
      "    136/191...\n",
      "    137/191...\n",
      "    138/191...\n",
      "    139/191...\n",
      "    140/191...\n",
      "    141/191...\n",
      "    142/191...\n",
      "    143/191...\n",
      "    144/191...\n",
      "    145/191...\n",
      "    146/191...\n",
      "    147/191...\n",
      "    148/191...\n",
      "    149/191...\n",
      "    150/191...\n",
      "    151/191...\n",
      "    152/191...\n",
      "    153/191...\n",
      "    154/191...\n",
      "    155/191...\n",
      "    156/191...\n",
      "    157/191...\n",
      "    158/191...\n",
      "    159/191...\n",
      "    160/191...\n",
      "    161/191...\n",
      "    162/191...\n",
      "    163/191...\n",
      "    164/191...\n",
      "    165/191...\n",
      "    166/191...\n",
      "    167/191...\n",
      "    168/191...\n",
      "    169/191...\n",
      "    170/191...\n",
      "    171/191...\n",
      "    172/191...\n",
      "    173/191...\n",
      "    174/191...\n",
      "    175/191...\n",
      "    176/191...\n",
      "    177/191...\n",
      "    178/191...\n",
      "    179/191...\n",
      "    180/191...\n",
      "    181/191...\n",
      "    182/191...\n",
      "    183/191...\n",
      "    184/191...\n",
      "    185/191...\n",
      "    186/191...\n",
      "    187/191...\n",
      "    188/191...\n",
      "    189/191...\n",
      "    190/191...\n",
      "    191/191...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "run_model(args.model_path, args.valid_data_folder, args.output_folder, allow_failures=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7c26c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import math\n",
    "import random\n",
    "\n",
    "def get_features(data, recordings):\n",
    "    \n",
    "    murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "    num_murmur_classes = len(murmur_classes)\n",
    "    outcome_classes = ['Abnormal', 'Normal']\n",
    "    num_outcome_classes = len(outcome_classes)\n",
    "    \n",
    "    age_classes = ['Neonate', 'Infant', 'Child', 'Adolescent', 'Young Adult']\n",
    "    recording_locations = ['AV', 'MV', 'PV', 'TV', 'PhC']\n",
    "    \n",
    "    num_recordings = len(recordings)\n",
    "    \n",
    "    \n",
    "    feature_dict={}\n",
    "    \n",
    "    feature_dict['mel']=[]\n",
    "    for i in range(num_recordings):\n",
    "        #log mel feature\n",
    "        log_mel_feature = librosa.power_to_db(librosa.feature.melspectrogram(y = recordings[i].astype(np.float32),\n",
    "                                                         sr= 4000,\n",
    "                                                             n_mels=128,\n",
    "                                                             n_fft=400, \n",
    "                                                             hop_length=128, \n",
    "                                                             win_length=400))\n",
    "        feature_dict['mel'].append(log_mel_feature)\n",
    "    \n",
    "    recording_info_lst = data.split('\\n')[1:num_recordings+1]\n",
    "    feature_dict['wav2vec2'] = []\n",
    "    for i in range(num_recordings):\n",
    "        pk_feature_fnm = recording_info_lst[i].split(' ')[2].replace('wav','pickle')\n",
    "        with open('/home/jh20/Data/nr_data/ECG/Physionet2022/physionet.org/files/circor-heart-sound/1.0.3/validation_wav2vec2/'+ pk_feature_fnm ,'rb') as fr:\n",
    "            feature = pickle.load(fr)\n",
    "        feature_dict['wav2vec2'].append(feature)\n",
    "    \n",
    "\n",
    "    # age\n",
    "    current_patient_age = get_age(data)\n",
    "    current_age_group = np.zeros(6, dtype=np.float32)\n",
    "    if current_patient_age in age_classes:\n",
    "        j = age_classes.index(current_patient_age)\n",
    "        current_age_group[j] = 1.0\n",
    "    else :\n",
    "        current_age_group[5] = 1.0\n",
    "\n",
    "    feature_dict['age']=current_age_group\n",
    "\n",
    "\n",
    "\n",
    "    # sex\n",
    "    sex = get_sex(data)\n",
    "    sex_feature = np.zeros(2, dtype=np.float32)\n",
    "    if compare_strings(sex, 'Female'):\n",
    "        sex_feature[0] = 1.0\n",
    "    elif compare_strings(sex, 'Male'):\n",
    "        sex_feature[1] = 1.0\n",
    "\n",
    "    feature_dict['sex']=sex_feature\n",
    "\n",
    "    # height and weight.\n",
    "    height = get_height(data)\n",
    "    weight = get_weight(data)\n",
    "\n",
    "    ## simple impute\n",
    "    if math.isnan(height) :\n",
    "        height = 110.846  #mean\n",
    "    if math.isnan(weight) :\n",
    "        weight = 23.767   #mean\n",
    "\n",
    "    height_weight = np.array([height, weight], dtype=np.float32)\n",
    "\n",
    "\n",
    "    feature_dict['hw']=height_weight\n",
    "\n",
    "    # Extract pregnancy\n",
    "    preg_feature = np.zeros(2, dtype=np.float32)\n",
    "    is_pregnant = get_pregnancy_status(data)\n",
    "    if is_pregnant == True:\n",
    "        preg_feature[0] = 1.0\n",
    "    elif is_pregnant == False:\n",
    "        preg_feature[1] = 1.0\n",
    "\n",
    "    feature_dict['preg']=preg_feature\n",
    "\n",
    "    # Extract location\n",
    "    feature_dict['loc']=[]\n",
    "    locations = get_locations(data)\n",
    "    for j in range(num_recordings):\n",
    "        \n",
    "        num_recording_locations = len(recording_locations)\n",
    "        loc_feature = np.zeros(num_recording_locations, dtype=np.float32)\n",
    "        if locations[j] in recording_locations:\n",
    "            idx = recording_locations.index(locations[j])\n",
    "            loc_feature[idx] = 1.0\n",
    "            \n",
    "        feature_dict['loc'].append(loc_feature)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # label\n",
    "\n",
    "    current_murmur = np.zeros(num_murmur_classes, dtype=np.float32)\n",
    "    murmur = get_murmur(data)\n",
    "    if murmur in murmur_classes:\n",
    "        j = murmur_classes.index(murmur)\n",
    "        current_murmur[j] = 1\n",
    "    \n",
    "    feature_dict['murmur']=current_murmur\n",
    "    \n",
    "    current_outcome = np.zeros(num_outcome_classes, dtype=np.float32)\n",
    "    outcome = get_outcome(data)\n",
    "    if outcome in outcome_classes:\n",
    "        j = outcome_classes.index(outcome)\n",
    "        current_outcome[j] = 1\n",
    "\n",
    "    feature_dict['outcome']=current_outcome\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    return feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15e478ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(label_folder, output_folder):\n",
    "    # Define murmur and outcome classes.\n",
    "    murmur_classes = ['Present', 'Unknown', 'Absent']\n",
    "    outcome_classes = ['Abnormal', 'Normal']\n",
    "\n",
    "    # Load and parse label and model output files.\n",
    "    label_files, output_files = find_challenge_files(label_folder, output_folder)\n",
    "    murmur_labels = load_murmurs(label_files, murmur_classes)\n",
    "    murmur_binary_outputs, murmur_scalar_outputs = load_classifier_outputs(output_files, murmur_classes)\n",
    "    outcome_labels = load_outcomes(label_files, outcome_classes)\n",
    "    outcome_binary_outputs, outcome_scalar_outputs = load_classifier_outputs(output_files, outcome_classes)\n",
    "\n",
    "    # For each patient, set the 'Present' or 'Abnormal' class to positive if no class is positive or if multiple classes are positive.\n",
    "    murmur_labels = enforce_positives(murmur_labels, murmur_classes, 'Present')\n",
    "    murmur_binary_outputs = enforce_positives(murmur_binary_outputs, murmur_classes, 'Present')\n",
    "    outcome_labels = enforce_positives(outcome_labels, outcome_classes, 'Abnormal')\n",
    "    outcome_binary_outputs = enforce_positives(outcome_binary_outputs, outcome_classes, 'Abnormal')\n",
    "\n",
    "    # Evaluate the murmur model by comparing the labels and model outputs.\n",
    "    murmur_auroc, murmur_auprc, murmur_auroc_classes, murmur_auprc_classes = compute_auc(murmur_labels, murmur_scalar_outputs)\n",
    "    murmur_f_measure, murmur_f_measure_classes = compute_f_measure(murmur_labels, murmur_binary_outputs)\n",
    "    murmur_accuracy, murmur_accuracy_classes = compute_accuracy(murmur_labels, murmur_binary_outputs)\n",
    "    murmur_weighted_accuracy = compute_weighted_accuracy(murmur_labels, murmur_binary_outputs, murmur_classes) # This is the murmur scoring metric.\n",
    "    murmur_cost = compute_cost(outcome_labels, murmur_binary_outputs, outcome_classes, murmur_classes) # Use *outcomes* to score *murmurs* for the Challenge cost metric, but this is not the actual murmur scoring metric.\n",
    "    murmur_scores = (murmur_classes, murmur_auroc, murmur_auprc, murmur_auroc_classes, murmur_auprc_classes, \\\n",
    "        murmur_f_measure, murmur_f_measure_classes, murmur_accuracy, murmur_accuracy_classes, murmur_weighted_accuracy, murmur_cost)\n",
    "\n",
    "    # Evaluate the outcome model by comparing the labels and model outputs.\n",
    "    outcome_auroc, outcome_auprc, outcome_auroc_classes, outcome_auprc_classes = compute_auc(outcome_labels, outcome_scalar_outputs)\n",
    "    outcome_f_measure, outcome_f_measure_classes = compute_f_measure(outcome_labels, outcome_binary_outputs)\n",
    "    outcome_accuracy, outcome_accuracy_classes = compute_accuracy(outcome_labels, outcome_binary_outputs)\n",
    "    outcome_weighted_accuracy = compute_weighted_accuracy(outcome_labels, outcome_binary_outputs, outcome_classes)\n",
    "    outcome_cost = compute_cost(outcome_labels, outcome_binary_outputs, outcome_classes, outcome_classes) # This is the clinical outcomes scoring metric.\n",
    "    outcome_scores = (outcome_classes, outcome_auroc, outcome_auprc, outcome_auroc_classes, outcome_auprc_classes, \\\n",
    "        outcome_f_measure, outcome_f_measure_classes, outcome_accuracy, outcome_accuracy_classes, outcome_weighted_accuracy, outcome_cost)\n",
    "\n",
    "    # Return the results.\n",
    "    return murmur_scores, outcome_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "27f2c39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Murmur scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.495,0.361,0.281,0.728,0.375,25689.450\n",
      "\n",
      "#Outcome scores\n",
      "AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\n",
      "0.544,0.569,0.520,0.602,0.863,11768.189\n",
      "\n",
      "#Murmur scores (per class)\n",
      "Classes,Present,Unknown,Absent\n",
      "AUROC,0.624,0.327,0.535\n",
      "AUPRC,0.289,0.058,0.735\n",
      "F-measure,0.000,0.000,0.842\n",
      "Accuracy,0.000,0.000,1.000\n",
      "\n",
      "#Outcome scores (per class)\n",
      "Classes,Abnormal,Normal\n",
      "AUROC,0.544,0.544\n",
      "AUPRC,0.534,0.603\n",
      "F-measure,0.719,0.321\n",
      "Accuracy,0.990,0.194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "murmur_scores, outcome_scores = evaluate_model(args.valid_data_folder, args.output_folder)\n",
    "\n",
    "classes, auroc, auprc, auroc_classes, auprc_classes, f_measure, f_measure_classes, accuracy, accuracy_classes, weighted_accuracy, cost = murmur_scores\n",
    "murmur_output_string = 'AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\\n{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}\\n'.format(auroc, auprc, f_measure, accuracy, weighted_accuracy, cost)\n",
    "murmur_class_output_string = 'Classes,{}\\nAUROC,{}\\nAUPRC,{}\\nF-measure,{}\\nAccuracy,{}\\n'.format(\n",
    "    ','.join(classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auroc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auprc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in f_measure_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in accuracy_classes))\n",
    "\n",
    "classes, auroc, auprc, auroc_classes, auprc_classes, f_measure, f_measure_classes, accuracy, accuracy_classes, weighted_accuracy, cost = outcome_scores\n",
    "outcome_output_string = 'AUROC,AUPRC,F-measure,Accuracy,Weighted Accuracy,Cost\\n{:.3f},{:.3f},{:.3f},{:.3f},{:.3f},{:.3f}\\n'.format(auroc, auprc, f_measure, accuracy, weighted_accuracy, cost)\n",
    "outcome_class_output_string = 'Classes,{}\\nAUROC,{}\\nAUPRC,{}\\nF-measure,{}\\nAccuracy,{}\\n'.format(\n",
    "    ','.join(classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auroc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in auprc_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in f_measure_classes),\n",
    "    ','.join('{:.3f}'.format(x) for x in accuracy_classes))\n",
    "\n",
    "output_string = '#Murmur scores\\n' + murmur_output_string + '\\n#Outcome scores\\n' + outcome_output_string \\\n",
    "    + '\\n#Murmur scores (per class)\\n' + murmur_class_output_string + '\\n#Outcome scores (per class)\\n' + outcome_class_output_string\n",
    "\n",
    "\n",
    "print(output_string)\n",
    "\n",
    "with open('./output_score/score,txt', 'wt') as f:\n",
    "    f.write(output_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f689224",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_features(data, recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4eda6630",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_files = find_patient_files(args.valid_data_folder)\n",
    "num_patient_files = len(patient_files)\n",
    "patient_data = load_patient_data(patient_files[1])\n",
    "recordings = load_recordings(args.valid_data_folder, patient_data)\n",
    "\n",
    "import random\n",
    "num_recordings = len(recordings)\n",
    "recordings_list=[]\n",
    "for i in range(num_recordings):\n",
    "    recording = recordings[i]\n",
    "    length = 20*4000  \n",
    "    if recording.shape[0] <= length:\n",
    "        shortage = length - recording.shape[0]\n",
    "        recording = np.pad(recording, (0, shortage), 'wrap')\n",
    "    start_frame = np.int64(random.random()*(recording.shape[0]-length))\n",
    "    recording = recording[start_frame:start_frame + length] \n",
    "    \n",
    "    recordings_list.append(recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "991036f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-2016,   710,   602, ...,   428,    89,  -253], dtype=int16),\n",
       " array([-5401, 19220,  9286, ..., -2441, -3624, -4292], dtype=int16)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recordings_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa8685e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 249, 768])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_features(patient_data, recordings_list)['wav2vec2'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0864000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48d66315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Challenge files.\n",
    "def find_challenge_files(label_folder, output_folder):\n",
    "    label_files = list()\n",
    "    output_files = list()\n",
    "    for label_file in sorted(os.listdir(label_folder)):\n",
    "        label_file_path = os.path.join(label_folder, label_file) # Full path for label file\n",
    "        if os.path.isfile(label_file_path) and label_file.lower().endswith('.txt') and not label_file.lower().startswith('.'):\n",
    "            root, ext = os.path.splitext(label_file)\n",
    "            output_file = root + '.csv'\n",
    "            output_file_path = os.path.join(output_folder, output_file) # Full path for corresponding output file\n",
    "            if os.path.isfile(output_file_path):\n",
    "                label_files.append(label_file_path)\n",
    "                output_files.append(output_file_path)\n",
    "            else:\n",
    "                raise IOError('Output file {} not found for label file {}.'.format(output_file, label_file))\n",
    "\n",
    "    if label_files and output_files:\n",
    "        return label_files, output_files\n",
    "    else:\n",
    "        raise IOError('No label or output files found.')\n",
    "\n",
    "# Load murmurs from label files.\n",
    "def load_murmurs(label_files, classes):\n",
    "    num_patients = len(label_files)\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # Use one-hot encoding for the labels.\n",
    "    labels = np.zeros((num_patients, num_classes), dtype=np.bool_)\n",
    "\n",
    "    # Iterate over the patients.\n",
    "    for i in range(num_patients):\n",
    "        data = load_patient_data(label_files[i])\n",
    "        label = get_murmur(data)\n",
    "        for j, x in enumerate(classes):\n",
    "            if compare_strings(label, x):\n",
    "                labels[i, j] = 1\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Load outcomes from label files.\n",
    "def load_outcomes(label_files, classes):\n",
    "    num_patients = len(label_files)\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # Use one-hot encoding for the labels.\n",
    "    labels = np.zeros((num_patients, num_classes), dtype=np.bool_)\n",
    "\n",
    "    # Iterate over the patients.\n",
    "    for i in range(num_patients):\n",
    "        data = load_patient_data(label_files[i])\n",
    "        label = get_outcome(data)\n",
    "        for j, x in enumerate(classes):\n",
    "            if compare_strings(label, x):\n",
    "                labels[i, j] = 1\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Load outputs from output files.\n",
    "def load_classifier_outputs(output_files, classes):\n",
    "    # The outputs should have the following form:\n",
    "    #\n",
    "    # #Record ID\n",
    "    # class_1, class_2, class_3\n",
    "    #       0,       1,       1\n",
    "    #    0.12,    0.34,    0.56\n",
    "    #\n",
    "    num_patients = len(output_files)\n",
    "    num_classes = len(classes)\n",
    "\n",
    "    # Use one-hot encoding for the outputs.\n",
    "    binary_outputs = np.zeros((num_patients, num_classes), dtype=np.bool_)\n",
    "    scalar_outputs = np.zeros((num_patients, num_classes), dtype=np.float64)\n",
    "\n",
    "    # Iterate over the patients.\n",
    "    for i in range(num_patients):\n",
    "        patient_id, patient_classes, patient_binary_outputs, patient_scalar_outputs = load_challenge_outputs(output_files[i])\n",
    "\n",
    "        # Allow for unordered or reordered classes.\n",
    "        for j, x in enumerate(classes):\n",
    "            for k, y in enumerate(patient_classes):\n",
    "                if compare_strings(x, y):\n",
    "                    binary_outputs[i, j] = patient_binary_outputs[k]\n",
    "                    scalar_outputs[i, j] = patient_scalar_outputs[k]\n",
    "\n",
    "    return binary_outputs, scalar_outputs\n",
    "\n",
    "# For each patient, set a specific class to positive if no class is positive or multiple classes are positive.\n",
    "def enforce_positives(outputs, classes, positive_class):\n",
    "    num_patients, num_classes = np.shape(outputs)\n",
    "    j = classes.index(positive_class)\n",
    "\n",
    "    for i in range(num_patients):\n",
    "        if np.sum(outputs[i, :]) != 1:\n",
    "            outputs[i, :] = 0\n",
    "            outputs[i, j] = 1\n",
    "    return outputs\n",
    "\n",
    "# Compute macro AUROC and macro AUPRC.\n",
    "def compute_auc(labels, outputs):\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    # Compute and summarize the confusion matrices for each class across at distinct output values.\n",
    "    auroc = np.zeros(num_classes)\n",
    "    auprc = np.zeros(num_classes)\n",
    "\n",
    "    for k in range(num_classes):\n",
    "        # We only need to compute TPs, FPs, FNs, and TNs at distinct output values.\n",
    "        thresholds = np.unique(outputs[:, k])\n",
    "        thresholds = np.append(thresholds, thresholds[-1]+1)\n",
    "        thresholds = thresholds[::-1]\n",
    "        num_thresholds = len(thresholds)\n",
    "\n",
    "        # Initialize the TPs, FPs, FNs, and TNs.\n",
    "        tp = np.zeros(num_thresholds)\n",
    "        fp = np.zeros(num_thresholds)\n",
    "        fn = np.zeros(num_thresholds)\n",
    "        tn = np.zeros(num_thresholds)\n",
    "        fn[0] = np.sum(labels[:, k] == 1)\n",
    "        tn[0] = np.sum(labels[:, k] == 0)\n",
    "\n",
    "        # Find the indices that result in sorted output values.\n",
    "        idx = np.argsort(outputs[:, k])[::-1]\n",
    "\n",
    "        # Compute the TPs, FPs, FNs, and TNs for class k across thresholds.\n",
    "        i = 0\n",
    "        for j in range(1, num_thresholds):\n",
    "            # Initialize TPs, FPs, FNs, and TNs using values at previous threshold.\n",
    "            tp[j] = tp[j-1]\n",
    "            fp[j] = fp[j-1]\n",
    "            fn[j] = fn[j-1]\n",
    "            tn[j] = tn[j-1]\n",
    "\n",
    "            # Update the TPs, FPs, FNs, and TNs at i-th output value.\n",
    "            while i < num_patients and outputs[idx[i], k] >= thresholds[j]:\n",
    "                if labels[idx[i], k]:\n",
    "                    tp[j] += 1\n",
    "                    fn[j] -= 1\n",
    "                else:\n",
    "                    fp[j] += 1\n",
    "                    tn[j] -= 1\n",
    "                i += 1\n",
    "\n",
    "        # Summarize the TPs, FPs, FNs, and TNs for class k.\n",
    "        tpr = np.zeros(num_thresholds)\n",
    "        tnr = np.zeros(num_thresholds)\n",
    "        ppv = np.zeros(num_thresholds)\n",
    "        for j in range(num_thresholds):\n",
    "            if tp[j] + fn[j]:\n",
    "                tpr[j] = float(tp[j]) / float(tp[j] + fn[j])\n",
    "            else:\n",
    "                tpr[j] = float('nan')\n",
    "            if fp[j] + tn[j]:\n",
    "                tnr[j] = float(tn[j]) / float(fp[j] + tn[j])\n",
    "            else:\n",
    "                tnr[j] = float('nan')\n",
    "            if tp[j] + fp[j]:\n",
    "                ppv[j] = float(tp[j]) / float(tp[j] + fp[j])\n",
    "            else:\n",
    "                ppv[j] = float('nan')\n",
    "\n",
    "        # Compute AUROC as the area under a piecewise linear function with TPR/\n",
    "        # sensitivity (x-axis) and TNR/specificity (y-axis) and AUPRC as the area\n",
    "        # under a piecewise constant with TPR/recall (x-axis) and PPV/precision\n",
    "        # (y-axis) for class k.\n",
    "        for j in range(num_thresholds-1):\n",
    "            auroc[k] += 0.5 * (tpr[j+1] - tpr[j]) * (tnr[j+1] + tnr[j])\n",
    "            auprc[k] += (tpr[j+1] - tpr[j]) * ppv[j+1]\n",
    "\n",
    "    # Compute macro AUROC and macro AUPRC across classes.\n",
    "    if np.any(np.isfinite(auroc)):\n",
    "        macro_auroc = np.nanmean(auroc)\n",
    "    else:\n",
    "        macro_auroc = float('nan')\n",
    "    if np.any(np.isfinite(auprc)):\n",
    "        macro_auprc = np.nanmean(auprc)\n",
    "    else:\n",
    "        macro_auprc = float('nan')\n",
    "\n",
    "    return macro_auroc, macro_auprc, auroc, auprc\n",
    "\n",
    "# Compute a binary confusion matrix, where the columns are the expert labels and the rows are the classifier labels.\n",
    "def compute_confusion_matrix(labels, outputs):\n",
    "    assert(np.shape(labels)[0] == np.shape(outputs)[0])\n",
    "    assert(all(value in (0, 1, True, False) for value in np.unique(labels)))\n",
    "    assert(all(value in (0, 1, True, False) for value in np.unique(outputs)))\n",
    "\n",
    "    num_patients = np.shape(labels)[0]\n",
    "    num_label_classes = np.shape(labels)[1]\n",
    "    num_output_classes = np.shape(outputs)[1]\n",
    "\n",
    "    A = np.zeros((num_output_classes, num_label_classes))\n",
    "    for k in range(num_patients):\n",
    "        for i in range(num_output_classes):\n",
    "            for j in range(num_label_classes):\n",
    "                if outputs[k, i] == 1 and labels[k, j] == 1:\n",
    "                    A[i, j] += 1\n",
    "\n",
    "    return A\n",
    "\n",
    "# Compute binary one-vs-rest confusion matrices, where the columns are the expert labels and the rows are the classifier labels.\n",
    "def compute_one_vs_rest_confusion_matrix(labels, outputs):\n",
    "    assert(np.shape(labels) == np.shape(outputs))\n",
    "    assert(all(value in (0, 1, True, False) for value in np.unique(labels)))\n",
    "    assert(all(value in (0, 1, True, False) for value in np.unique(outputs)))\n",
    "\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    A = np.zeros((num_classes, 2, 2))\n",
    "    for i in range(num_patients):\n",
    "        for j in range(num_classes):\n",
    "            if labels[i, j] == 1 and outputs[i, j] == 1: # TP\n",
    "                A[j, 0, 0] += 1\n",
    "            elif labels[i, j] == 0 and outputs[i, j] == 1: # FP\n",
    "                A[j, 0, 1] += 1\n",
    "            elif labels[i, j] == 1 and outputs[i, j] == 0: # FN\n",
    "                A[j, 1, 0] += 1\n",
    "            elif labels[i, j] == 0 and outputs[i, j] == 0: # TN\n",
    "                A[j, 1, 1] += 1\n",
    "\n",
    "    return A\n",
    "\n",
    "# Compute macro F-measure.\n",
    "def compute_f_measure(labels, outputs):\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "\n",
    "    A = compute_one_vs_rest_confusion_matrix(labels, outputs)\n",
    "\n",
    "    f_measure = np.zeros(num_classes)\n",
    "    for k in range(num_classes):\n",
    "        tp, fp, fn, tn = A[k, 0, 0], A[k, 0, 1], A[k, 1, 0], A[k, 1, 1]\n",
    "        if 2 * tp + fp + fn > 0:\n",
    "            f_measure[k] = float(2 * tp) / float(2 * tp + fp + fn)\n",
    "        else:\n",
    "            f_measure[k] = float('nan')\n",
    "\n",
    "    if np.any(np.isfinite(f_measure)):\n",
    "        macro_f_measure = np.nanmean(f_measure)\n",
    "    else:\n",
    "        macro_f_measure = float('nan')\n",
    "\n",
    "    return macro_f_measure, f_measure\n",
    "\n",
    "# Compute accuracy.\n",
    "def compute_accuracy(labels, outputs):\n",
    "    # Compute confusion matrix.\n",
    "    assert(np.shape(labels) == np.shape(outputs))\n",
    "    num_patients, num_classes = np.shape(labels)\n",
    "    A = compute_confusion_matrix(labels, outputs)\n",
    "\n",
    "    # Compute accuracy.\n",
    "    if np.sum(A) > 0:\n",
    "        accuracy = np.trace(A) / np.sum(A)\n",
    "    else:\n",
    "        accuracy = float('nan')\n",
    "\n",
    "    # Compute per-class accuracy.\n",
    "    accuracy_classes = np.zeros(num_classes)\n",
    "    for i in range(num_classes):\n",
    "        if np.sum(A[:, i]) > 0:\n",
    "            accuracy_classes[i] = A[i, i] / np.sum(A[:, i])\n",
    "        else:\n",
    "            accuracy_classes[i] = float('nan')\n",
    "\n",
    "    return accuracy, accuracy_classes\n",
    "\n",
    "# Compute accuracy.\n",
    "def compute_weighted_accuracy(labels, outputs, classes):\n",
    "    # Define constants.\n",
    "    if classes == ['Present', 'Unknown', 'Absent']:\n",
    "        weights = np.array([[5, 3, 1], [5, 3, 1], [5, 3, 1]])\n",
    "    elif classes == ['Abnormal', 'Normal']:\n",
    "        weights = np.array([[5, 1], [5, 1]])\n",
    "    else:\n",
    "        raise NotImplementedError('Weighted accuracy undefined for classes {}'.format(', '.join(classes)))\n",
    "\n",
    "    # Compute confusion matrix.\n",
    "    assert(np.shape(labels) == np.shape(outputs))\n",
    "    A = compute_confusion_matrix(labels, outputs)\n",
    "\n",
    "    # Multiply the confusion matrix by the weight matrix.\n",
    "    assert(np.shape(A) == np.shape(weights))\n",
    "    B = weights * A\n",
    "\n",
    "    # Compute weighted_accuracy.\n",
    "    if np.sum(B) > 0:\n",
    "        weighted_accuracy = np.trace(B) / np.sum(B)\n",
    "    else:\n",
    "        weighted_accuracy = float('nan')\n",
    "\n",
    "    return weighted_accuracy\n",
    "\n",
    "# Define total cost for algorithmic prescreening of m patients.\n",
    "def cost_algorithm(m):\n",
    "    return 10*m\n",
    "\n",
    "# Define total cost for expert screening of m patients out of a total of n total patients.\n",
    "def cost_expert(m, n):\n",
    "    return (25 + 397*(m/n) -1718*(m/n)**2 + 11296*(m/n)**4) * n\n",
    "\n",
    "# Define total cost for treatment of m patients.\n",
    "def cost_treatment(m):\n",
    "    return 10000*m\n",
    "\n",
    "# Define total cost for missed/late treatement of m patients.\n",
    "def cost_error(m):\n",
    "    return 50000*m\n",
    "\n",
    "# Compute Challenge cost metric.\n",
    "def compute_cost(labels, outputs, label_classes, output_classes):\n",
    "    # Define positive and negative classes for referral and treatment.\n",
    "    positive_classes = ['Present', 'Unknown', 'Abnormal']\n",
    "    negative_classes = ['Absent', 'Normal']\n",
    "\n",
    "    # Compute confusion matrix.\n",
    "    A = compute_confusion_matrix(labels, outputs)\n",
    "\n",
    "    # Identify positive and negative classes for referral.\n",
    "    idx_label_positive = [i for i, x in enumerate(label_classes) if x in positive_classes]\n",
    "    idx_label_negative = [i for i, x in enumerate(label_classes) if x in negative_classes]\n",
    "    idx_output_positive = [i for i, x in enumerate(output_classes) if x in positive_classes]\n",
    "    idx_output_negative = [i for i, x in enumerate(output_classes) if x in negative_classes]\n",
    "\n",
    "    # Identify true positives, false positives, false negatives, and true negatives.\n",
    "    tp = np.sum(A[np.ix_(idx_output_positive, idx_label_positive)])\n",
    "    fp = np.sum(A[np.ix_(idx_output_positive, idx_label_negative)])\n",
    "    fn = np.sum(A[np.ix_(idx_output_negative, idx_label_positive)])\n",
    "    tn = np.sum(A[np.ix_(idx_output_negative, idx_label_negative)])\n",
    "    total_patients = tp + fp + fn + tn\n",
    "\n",
    "    # Compute total cost for all patients.\n",
    "    total_cost = cost_algorithm(total_patients) \\\n",
    "        + cost_expert(tp + fp, total_patients) \\\n",
    "        + cost_treatment(tp) \\\n",
    "        + cost_error(fn)\n",
    "\n",
    "    # Compute mean cost per patient.\n",
    "    if total_patients > 0:\n",
    "        mean_cost = total_cost / total_patients\n",
    "    else:\n",
    "        mean_cost = float('nan')\n",
    "\n",
    "    return mean_cost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5a4465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
